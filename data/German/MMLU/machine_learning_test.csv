Aussage 1| Der lineare Regressionsschätzer weist unter allen erwartungstreuen Schätzern die geringste Varianz auf. Aussage 2| Die den von AdaBoost zusammengestellten Klassifikatoren zugewiesenen Koeffizienten α sind immer nicht negativ.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,D
"Aussage 1| RoBERTa trainiert vorab auf einem Korpus, der ungefähr zehnmal größer ist als der Korpus, auf dem BERT vorab trainiert wurde. Aussage 2| ResNeXts verwendete im Jahr 2018 normalerweise Tanh-Aktivierungsfunktionen.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,C
"Aussage 1| Support-Vektor-Maschinen liefern wie logistische Regressionsmodelle eine Wahrscheinlichkeitsverteilung über die möglichen Bezeichnungen anhand eines Eingabebeispiels. Aussage 2| Wir würden erwarten, dass die Unterstützungsvektoren im Allgemeinen gleich bleiben, wenn wir von einem linearen Kernel zu polynomialen Kerneln höherer Ordnung wechseln.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Ein maschinelles Lernproblem umfasst vier Attribute plus eine Klasse. Die Attribute haben jeweils 3, 2, 2 und 2 mögliche Werte. Die Klasse hat 3 mögliche Werte. Wie viele maximal mögliche unterschiedliche Beispiele gibt es?",12,24,48,72,D
Welche Architektur eignet sich ab 2020 am besten für die Klassifizierung hochauflösender Bilder?,Faltungsnetzwerke,Graphnetzwerke,vollständig verbundene Netzwerke,RBF-Netzwerke,A
"Aussage 1| Die Log-Likelihood der Daten wird durch aufeinanderfolgende Iterationen des Erwartungsmaximierungsalgorithmus immer zunehmen. Aussage 2| Ein Nachteil von Q-Learning besteht darin, dass es nur eingesetzt werden kann, wenn der Lernende vorher weiß, wie sich seine Handlungen auf seine Umgebung auswirken.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Nehmen wir an, wir haben den Gradienten unserer Kostenfunktion berechnet und in einem Vektor g gespeichert. Wie hoch sind die Kosten für eine Aktualisierung des Gradientenabstiegs angesichts des Gradienten?",O(D),AN),O(ND),O(ND^2),A
"Aussage 1| Für eine kontinuierliche Zufallsvariable x und ihre Wahrscheinlichkeitsverteilungsfunktion p(x) gilt, dass 0 ≤ p(x) ≤ 1 für alle x. Aussage 2| Der Entscheidungsbaum wird durch Minimierung des Informationsgewinns erlernt.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
Betrachten Sie das unten angegebene Bayes'sche Netzwerk. Wie viele unabhängige Parameter werden für dieses Bayes'sche Netzwerk H -> U <- P <- W benötigt?,2,4,8,16,C
"Wenn die Anzahl der Trainingsbeispiele unendlich wird, verfügt Ihr anhand dieser Daten trainiertes Modell über Folgendes:",Geringere Varianz,Höhere Varianz,Gleiche Varianz,Nichts des oben Genannten,A
"Aussage 1| Die Menge aller Rechtecke in der 2D-Ebene (einschließlich nicht achsenausgerichteter Rechtecke) kann eine Menge von 5 Punkten zerstören. Aussage 2| Die VC-Dimension des k-Nearest Neighbor-Klassifikators, wenn k = 1 ist unendlich.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"_ bezieht sich auf ein Modell, das weder die Trainingsdaten modellieren noch auf neue Daten verallgemeinern kann.",gute Passform,Überanpassung,Unteranpassung,alle oben genannten,C
Aussage 1| Der F1-Score kann besonders nützlich für Datensätze mit einem hohen Klassenungleichgewicht sein. Aussage 2| Die Fläche unter der ROC-Kurve ist eine der Hauptmetriken zur Bewertung von Anomaliedetektoren.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Aussage 1| Der Backpropagation-Algorithmus lernt ein global optimales neuronales Netzwerk mit verborgenen Schichten. Aussage 2| Die VC-Dimension einer Linie sollte höchstens 2 betragen, da ich mindestens einen Fall mit 3 Punkten finden kann, die von keiner Linie zertrümmert werden können.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Hohe Entropie bedeutet, dass die Partitionen in der Klassifizierung gleich sind",rein,nicht rein,nützlich,nutzlos,B
"Aussage 1| Im ursprünglichen ResNet-Papier wird die Layer-Normalisierung verwendet, nicht die Batch-Normalisierung. Aussage 2| DCGANs nutzen die Selbstaufmerksamkeit, um das Training zu stabilisieren.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Beim Erstellen eines linearen Regressionsmodells für einen bestimmten Datensatz beobachten Sie, dass der Koeffizient eines der Merkmale einen relativ hohen negativen Wert aufweist. Das deutet darauf hin",Dieses Feature hat einen starken Einfluss auf das Modell (sollte beibehalten werden),Diese Funktion hat keinen großen Einfluss auf das Modell (sollte ignoriert werden),"Ohne zusätzliche Informationen ist es nicht möglich, die Bedeutung dieser Funktion zu beurteilen",Es lässt sich nichts feststellen.,C
Welche dieser Strukturannahmen hat für ein neuronales Netzwerk den größten Einfluss auf den Kompromiss zwischen Unteranpassung (d. h. einem Modell mit hoher Verzerrung) und Überanpassung (d. h. einem Modell mit hoher Varianz):,Die Anzahl der ausgeblendeten Knoten,Die Lernrate,Die anfängliche Auswahl an Gewichten,Die Verwendung einer Konstantterm-Einheiteneingabe,A
Welche dieser Strukturannahmen hat bei der polynomialen Regression den größten Einfluss auf den Kompromiss zwischen Unteranpassung und Überanpassung:,Der Polynomgrad,Ob wir die Gewichte durch Matrixinversion oder Gradientenabstieg lernen,Die angenommene Varianz des Gaußschen Rauschens,Die Verwendung einer Konstantterm-Einheiteneingabe,A
Aussage 1| Ab 2020 erreichen einige Modelle auf CIFAR-10 eine Genauigkeit von mehr als 98 %. Aussage 2| Die ursprünglichen ResNets wurden nicht mit dem Adam-Optimierer optimiert.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
Der K-Means-Algorithmus:,"Erfordert, dass die Dimension des Merkmalsraums nicht größer ist als die Anzahl der Stichproben","Hat den kleinsten Wert der Zielfunktion, wenn K = 1",Minimiert die Varianz innerhalb der Klasse für eine bestimmte Anzahl von Clustern,"Konvergiert genau dann zum globalen Optimum, wenn als Anfangsmittel einige der Stichproben selbst ausgewählt werden",C
Aussage 1| VGGNets haben Faltungskerne mit geringerer Breite und Höhe als die First-Layer-Kernel von AlexNet. Aussage 2| Vor der Batch-Normalisierung wurden datenabhängige Gewichtsinitialisierungsverfahren eingeführt.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Welchen Rang hat die folgende Matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]",0,1,2,3,B
"Aussage 1| Für die Klassifizierung kann eine Dichteschätzung (z. B. mit dem Kernel-Dichteschätzer) verwendet werden. Aussage 2| Die Entsprechung zwischen logistischer Regression und Gaußscher naiver Bayes-Methode (mit Identitätsklassen-Kovarianzen) bedeutet, dass zwischen den Parametern der beiden Klassifikatoren eine Eins-zu-Eins-Entsprechung besteht.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,C
"Angenommen, wir möchten ein Clustering für räumliche Daten durchführen, beispielsweise für die geometrischen Standorte von Häusern. Wir möchten Cluster in vielen verschiedenen Größen und Formen herstellen. Welche der folgenden Methoden ist die geeignetste?",Entscheidungsbäume,Dichtebasiertes Clustering,Modellbasiertes Clustering,K-bedeutet Clustering,B
Aussage 1| In AdaBoost erhöhen sich die Gewichte der falsch klassifizierten Beispiele um denselben multiplikativen Faktor. Aussage 2| In AdaBoost nimmt der gewichtete Trainingsfehler e_t des t-ten schwachen Klassifikators bei Trainingsdaten mit Gewichten D_t tendenziell als Funktion von t zu.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"MLE-Schätzungen sind oft unerwünscht, weil",sie sind voreingenommen,sie weisen eine hohe Varianz auf,Sie sind keine konsistenten Schätzer,Nichts des oben Genannten,B
Die rechnerische Komplexität des Gradientenabstiegs beträgt:,linear in D,linear in N,Polynom in D,abhängig von der Anzahl der Iterationen,C
Die Mittelung der Ausgabe mehrerer Entscheidungsbäume hilft _.,Erhöhen Sie die Voreingenommenheit,Voreingenommenheit verringern,Varianz erhöhen,Varianz verringern,D
"Das durch Anwendung der linearen Regression auf die identifizierte Teilmenge von Merkmalen erhaltene Modell kann sich von dem Modell unterscheiden, das am Ende des Prozesses der Identifizierung der Teilmenge während des Prozesses erhalten wurde",Auswahl der besten Teilmenge,Schrittweise Auswahl weiterleiten,Vorwärtsstufenweise Auswahl,Alle oben genannten,C
Neuronale Netze:,Optimieren Sie eine konvexe Zielfunktion,Kann nur mit stochastischem Gradientenabstieg trainiert werden,Kann eine Mischung verschiedener Aktivierungsfunktionen verwenden,Nichts des oben Genannten,C
"Angenommen, die Inzidenz einer Krankheit D beträgt etwa 5 Fälle pro 100 Menschen (d. h. P(D) = 0,05). Angenommen, die boolesche Zufallsvariable D bedeutet, dass ein Patient „Krankheit D hat“, und die boolesche Zufallsvariable TP steht für „Tests positiv“. Es ist bekannt, dass Tests für Krankheit D sehr genau sind, da die Wahrscheinlichkeit, positiv zu testen, wenn Sie an der Krankheit leiden, 0,99 beträgt und die Wahrscheinlichkeit, negativ zu testen, wenn Sie nicht an der Krankheit leiden, 0,97 beträgt. Was ist P(TP), die A-priori-Wahrscheinlichkeit, positiv zu testen?",0.0368,0.473,0.078,Nichts des oben Genannten,C
Aussage 1| Nach der Abbildung in den Merkmalsraum Q über eine Kernelfunktion mit radialer Basis kann 1-NN unter Verwendung des ungewichteten euklidischen Abstands möglicherweise eine bessere Klassifizierungsleistung als im ursprünglichen Raum erzielen (obwohl wir dies nicht garantieren können). Aussage 2| Die VC-Dimension eines Perceptrons ist kleiner als die VC-Dimension einer einfachen linearen SVM.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
Der Nachteil der Rastersuche ist,Es kann nicht auf nicht differenzierbare Funktionen angewendet werden.,Es kann nicht auf nicht kontinuierliche Funktionen angewendet werden.,Es ist schwer umzusetzen.,Für die multiple lineare Regression läuft es einigermaßen langsam.,D
"Die Niederschlagsmenge in einer Region anhand verschiedener Hinweise vorherzusagen, ist ein ______ Problem.",Überwachtes Lernen,Unbeaufsichtigtes Lernen,Clustering,Nichts des oben Genannten,A
Welcher der folgenden Sätze ist in Bezug auf Regression FALSCH?,Es verknüpft Eingaben mit Ausgaben.,Es wird zur Vorhersage verwendet.,Es kann zur Interpretation verwendet werden.,Es entdeckt kausale Zusammenhänge,D
Welcher der folgenden Gründe ist der Hauptgrund für das Beschneiden eines Entscheidungsbaums?,Um beim Testen Rechenzeit zu sparen,Um Platz für die Speicherung des Entscheidungsbaums zu sparen,Um den Trainingssatzfehler zu verkleinern,Um eine Überanpassung des Trainingssatzes zu vermeiden,D
"Aussage 1| Der Kernel-Dichteschätzer entspricht der Durchführung einer Kernel-Regression mit dem Wert Yi = 1/n an jedem Punkt Xi im Originaldatensatz. Aussage 2| Die Tiefe eines erlernten Entscheidungsbaums kann größer sein als die Anzahl der Trainingsbeispiele, die zum Erstellen des Baums verwendet wurden.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Angenommen, Ihr Modell ist überangepasst. Welche der folgenden Methoden ist KEINE gültige Methode, um die Überanpassung zu reduzieren?",Erhöhen Sie die Menge an Trainingsdaten.,Verbessern Sie den verwendeten Optimierungsalgorithmus zur Fehlerminimierung.,Verringern Sie die Modellkomplexität.,Reduzieren Sie das Rauschen in den Trainingsdaten.,B
Aussage 1| Die Softmax-Funktion wird häufig in der logistischen Regression mehrerer Klassen verwendet. Aussage 2| Die Temperatur einer ungleichmäßigen Softmax-Verteilung beeinflusst deren Entropie.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
Welche der folgenden Aussagen zu einer SVM ist/sind wahr?,Für zweidimensionale Datenpunkte ist die von einer linearen SVM gelernte trennende Hyperebene eine gerade Linie.,Theoretisch kann eine Gaußsche Kernel-SVM keine komplexe trennende Hyperebene modellieren.,Für jede in einer SVM verwendete Kernelfunktion kann man eine äquivalente Basiserweiterung in geschlossener Form erhalten.,Überanpassung in einer SVM ist keine Funktion der Anzahl der Unterstützungsvektoren.,A
"Welche der folgenden ist die gemeinsame Wahrscheinlichkeit von H, U, P und W, die durch das gegebene Bayes'sche Netzwerk H -> U <- P <- W beschrieben wird? [Anmerkung: als Produkt der bedingten Wahrscheinlichkeiten]","P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)",Nichts des oben Genannten,C
"Aussage 1| Da die VC-Dimension für eine SVM mit einem radialen Basiskern unendlich ist, muss eine solche SVM schlechter sein als eine SVM mit polynomialem Kernel, die eine endliche VC-Dimension hat. Aussage 2| Ein zweischichtiges neuronales Netzwerk mit linearen Aktivierungsfunktionen ist im Wesentlichen eine gewichtete Kombination linearer Trennzeichen, die auf einem bestimmten Datensatz trainiert werden. Der auf linearen Trennzeichen basierende Boosting-Algorithmus findet auch eine Kombination von linearen Trennzeichen, daher liefern diese beiden Algorithmen das gleiche Ergebnis.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Aussage 1| Der ID3-Algorithmus findet garantiert den optimalen Entscheidungsbaum. Aussage 2| Betrachten Sie eine kontinuierliche Wahrscheinlichkeitsverteilung mit einer Dichte f(), die überall ungleich Null ist. Die Wahrscheinlichkeit eines Wertes x ist gleich f(x).","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Welcher der folgenden Algorithmen (mit den richtigen Hyperparametern und der richtigen Initialisierung) kann bei einem neuronalen Netz mit N Eingabeknoten, keinen verborgenen Schichten, einem Ausgabeknoten und Entropieverlust- und Sigmoid-Aktivierungsfunktionen verwendet werden, um das globale Optimum zu finden?",Stochastischer Gradientenabstieg,Mini-Batch-Gradientenabstieg,Batch-Gradientenabstieg,Alle oben genannten,D
"Wenn Sie einem linearen Modell weitere Basisfunktionen hinzufügen möchten, wählen Sie die wahrscheinlichste Option aus:",Verringert die Modellverzerrung,Verringert die Schätzungsverzerrung,Verringert die Varianz,Hat keinen Einfluss auf Voreingenommenheit und Varianz,A
"Betrachten Sie das unten angegebene Bayes'sche Netzwerk. Wie viele unabhängige Parameter würden wir benötigen, wenn wir keine Annahmen über die Unabhängigkeit oder bedingte Unabhängigkeit H -> U <- P <- W machen würden?",3,4,7,15,D
Ein anderer Begriff für Out-of-Distribution-Erkennung ist?,Anomalieerkennung,Ein-Klassen-Erkennung,Robustheit der Zugtest-Mismatch-Robustheit,Hintergrunderkennung,A
"Aussage 1| Wir lernen einen Klassifikator f, indem wir schwache Lernende h fördern. Die funktionale Form der Entscheidungsgrenze von f ist dieselbe wie die von h, jedoch mit unterschiedlichen Parametern. (Wenn z. B. h ein linearer Klassifikator wäre, dann ist f auch ein linearer Klassifikator). Aussage 2| Mithilfe der Kreuzvalidierung kann die Anzahl der Iterationen beim Boosten ausgewählt werden. Dieses Verfahren kann dazu beitragen, eine Überanpassung zu reduzieren.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,D
Aussage 1| Autobahnnetze wurden nach ResNets eingeführt und verzichten auf maximales Pooling zugunsten von Faltungen. Aussage 2| DenseNets kosten normalerweise mehr Speicher als ResNets.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,D
"Wenn N die Anzahl der Instanzen im Trainingsdatensatz ist, hat die Klassifizierung „Nächste Nachbarn“ eine Klassifizierungslaufzeit von",O(1),AN),O(log N ),O( N^2 ),B
"Aussage 1| Die ursprünglichen ResNets und Transformers sind Feedforward-Neuronale Netze. Aussage 2| Die ursprünglichen Transformer verwenden Selbstaufmerksamkeit, das ursprüngliche ResNet jedoch nicht.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Aussage 1| RELUs sind nicht monoton, aber Sigmoide sind monoton. Aussage 2| Mit Gradientenabstieg trainierte neuronale Netze konvergieren mit hoher Wahrscheinlichkeit zum globalen Optimum.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,D
Die numerische Ausgabe eines Sigmoidknotens in einem neuronalen Netzwerk:,Ist unbegrenzt und umfasst alle reellen Zahlen.,Ist unbegrenzt und umfasst alle ganzen Zahlen.,Ist zwischen 0 und 1 begrenzt.,Ist zwischen -1 und 1 begrenzt.,C
"Welche der folgenden Aussagen können nur verwendet werden, wenn Trainingsdaten linear trennbar sind?",Lineare SVM mit harter Marge.,Lineare logistische Regression.,Lineare SVM mit weichem Rand.,Die Schwerpunktmethode.,A
Welche der folgenden räumlichen Clustering-Algorithmen gibt es?,Partitionierungsbasiertes Clustering,K-bedeutet Clustering,Rasterbasiertes Clustering,Alle oben genannten,D
"Aussage 1| Die maximalen Margin-Entscheidungsgrenzen, die die Konstruktion von Vektormaschinen unterstützen, weisen den niedrigsten Generalisierungsfehler unter allen linearen Klassifikatoren auf. Aussage 2| Jede Entscheidungsgrenze, die wir aus einem generativen Modell mit klassenbedingten Gauß-Verteilungen erhalten, könnte im Prinzip mit einer SVM und einem Polynomkern vom Grad kleiner oder gleich drei reproduziert werden.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,D
"Aussage 1| Die L2-Regularisierung linearer Modelle führt tendenziell dazu, dass die Modelle spärlicher sind als die L1-Regularisierung. Aussage 2| Restverbindungen finden Sie in ResNets und Transformers.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,D
"Angenommen, wir möchten P(H|E, F) berechnen und haben keine Informationen zur bedingten Unabhängigkeit. Welche der folgenden Zahlenmengen reichen für die Berechnung aus?","P(E, F), P(H), P(E|H), P(F|H)","P(E, F), P(H), P(E, F|H)","P(H), P(E|H), P(F|H)","P(E, F), P(E|H), P(F|H)",B
Welche der folgenden Maßnahmen verhindert eine Überanpassung beim Bagging?,Die Verwendung von Probenahme mit Ersatz als Probenahmetechnik,Die Verwendung schwacher Klassifikatoren,"Die Verwendung von Klassifizierungsalgorithmen, die nicht zur Überanpassung neigen",Die an jedem trainierten Klassifikator durchgeführte Validierungspraxis,B
"Aussage 1| PCA und Spectral Clustering (wie Andrew Ngs) führen eine Eigenzerlegung auf zwei verschiedenen Matrizen durch. Die Größe dieser beiden Matrizen ist jedoch gleich. Aussage 2| Da die Klassifizierung ein Sonderfall der Regression ist, ist die logistische Regression ein Sonderfall der linearen Regression.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Aussage 1| Die Stanford Sentiment Treebank enthielt Filmrezensionen, keine Buchrezensionen. Aussage 2| Die Penn Treebank wurde zur Sprachmodellierung verwendet.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Welche Dimensionalität hat der Nullraum der folgenden Matrix? A = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]]",0,1,2,3,C
Was sind Unterstützungsvektoren?,"Die Beispiele, die am weitesten von der Entscheidungsgrenze entfernt sind.","Die einzigen Beispiele, die zur Berechnung von f(x) in einer SVM erforderlich sind.",Der Datenschwerpunkt.,"Alle Beispiele, die in einer SVM ein Gewicht αk ungleich Null haben.",B
Aussage 1| Word2Vec-Parameter wurden nicht mit einer eingeschränkten Boltzman-Maschine initialisiert. Aussage 2| Die Tanh-Funktion ist eine nichtlineare Aktivierungsfunktion.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Wenn Ihr Trainingsverlust mit der Anzahl der Epochen zunimmt, welcher der folgenden Punkte könnte ein mögliches Problem beim Lernprozess sein?",Die Regularisierung ist zu niedrig und das Modell passt zu stark,Die Regularisierung ist zu hoch und das Modell ist unzureichend,Die Schrittgröße ist zu groß,Die Schrittweite ist zu klein,C
"Angenommen, die Inzidenz einer Krankheit D beträgt etwa 5 Fälle pro 100 Menschen (d. h. P(D) = 0,05). Angenommen, die boolesche Zufallsvariable D bedeutet, dass ein Patient „Krankheit D hat“, und die boolesche Zufallsvariable TP steht für „Tests positiv“. Es ist bekannt, dass Tests für Krankheit D sehr genau sind, da die Wahrscheinlichkeit, positiv zu testen, wenn Sie an der Krankheit leiden, 0,99 beträgt und die Wahrscheinlichkeit, negativ zu testen, wenn Sie nicht an der Krankheit leiden, 0,97 beträgt. Was ist P(D | TP), die A-posteriori-Wahrscheinlichkeit, dass Sie an Krankheit D leiden, wenn der Test positiv ist?",0.0495,0.078,0.635,0.97,C
"Aussage 1| Herkömmliche Ergebnisse des maschinellen Lernens gehen davon aus, dass die Zug- und Testsätze unabhängig und identisch verteilt sind. Aussage 2| Im Jahr 2017 wurden COCO-Modelle normalerweise auf ImageNet vorab trainiert.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Aussage 1| Die Werte der Margen, die von zwei verschiedenen Kerneln K1(x, x0) und K2(x, x0) auf demselben Trainingssatz erhalten werden, sagen uns nicht, welcher Klassifikator auf dem Testsatz besser abschneidet. Aussage 2| Die Aktivierungsfunktion von BERT ist GELU.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
Welcher der folgenden ist ein Clustering-Algorithmus beim maschinellen Lernen?,Erwartungsmaximierung,WAGEN,Gaußscher naiver Bayes,A priori,A
"Sie haben gerade das Training eines Entscheidungsbaums für die Spam-Klassifizierung abgeschlossen und er weist sowohl in Ihren Trainings- als auch in Ihren Testsätzen eine ungewöhnlich schlechte Leistung auf. Sie wissen, dass Ihre Implementierung keine Fehler aufweist. Was könnte also die Ursache des Problems sein?",Ihre Entscheidungsbäume sind zu flach.,Sie müssen die Lernrate erhöhen.,Du überpassst.,Nichts des oben Genannten.,A
Die K-fache Kreuzvalidierung ist,linear in K,quadratisch in K,kubisch in K,exponentiell in K,A
Aussage 1| Neuronale Netze im industriellen Maßstab werden normalerweise auf CPUs und nicht auf GPUs trainiert. Aussage 2| Das ResNet-50-Modell verfügt über über 1 Milliarde Parameter.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
"Gegeben zwei boolesche Zufallsvariablen, A und B, mit P(A) = 1/2, P(B) = 1/3 und P(A | ¬B) = 1/4, was ist P(A | B) ?",1/6,1/4,3/4,1,D
Mit welchem ​​der folgenden Professoren sind existenzielle Risiken durch KI am häufigsten verbunden?,Nando de Freitas,Innerhalb Y Ann l ECU,Stuart Russell,Jitendra Malik,C
"Aussage 1| Die Maximierung der Wahrscheinlichkeit eines logistischen Regressionsmodells führt zu mehreren lokalen Optima. Aussage 2| Kein Klassifikator kann eine bessere Leistung erbringen als ein naiver Bayes-Klassifikator, wenn die Verteilung der Daten bekannt ist.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
Welche dieser Strukturannahmen hat für die Kernel-Regression den größten Einfluss auf den Kompromiss zwischen Unter- und Überanpassung:,Ob die Kernelfunktion gaußförmig oder dreieckig oder kastenförmig ist,"Ob wir euklidische, L1- oder L∞-Metriken verwenden",Die Kernelbreite,Die maximale Höhe der Kernelfunktion,C
Aussage 1| Der SVM-Lernalgorithmus findet garantiert die global optimale Hypothese in Bezug auf seine Objektfunktion. Aussage 2| Nach der Abbildung in den Merkmalsraum Q durch eine Kernelfunktion auf radialer Basis kann ein Perceptron möglicherweise eine bessere Klassifizierungsleistung als in seinem ursprünglichen Raum erzielen (obwohl wir dies nicht garantieren können).,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
Welche dieser Strukturannahmen hat für einen Gaußschen Bayes-Klassifikator den größten Einfluss auf den Kompromiss zwischen Unteranpassung und Überanpassung:,Ob wir die Klassenzentren durch Maximum Likelihood oder Gradient Descent lernen,Ob wir von Kovarianzmatrizen voller Klassen oder von Kovarianzmatrizen diagonaler Klassen ausgehen,"Ob wir gleiche Klassenprioris oder Priors haben, die aus den Daten geschätzt werden.","Ob wir zulassen, dass Klassen unterschiedliche Mittelwertvektoren haben, oder ob wir sie zwingen, denselben Mittelwertvektor zu verwenden",B
"Aussage 1| Eine Überanpassung ist wahrscheinlicher, wenn der Satz an Trainingsdaten klein ist. Aussage 2| Eine Überanpassung ist wahrscheinlicher, wenn der Hypothesenraum klein ist.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,D
"Aussage 1| Neben EM kann der Gradientenabstieg verwendet werden, um Rückschlüsse oder Lernen auf dem Gaußschen Mischungsmodell durchzuführen. Aussage 2 | Unter der Annahme einer festen Anzahl von Attributen kann ein auf Gauß basierender optimaler Bayes-Klassifikator zeitlich linear anhand der Anzahl der Datensätze im Datensatz erlernt werden.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Aussage 1| In einem Bayes'schen Netzwerk sind die Inferenzergebnisse des Junction-Tree-Algorithmus dieselben wie die Inferenzergebnisse der Variableneliminierung. Aussage 2| Wenn zwei Zufallsvariablen X und Y bei einer anderen Zufallsvariablen Z bedingt unabhängig sind, dann sind im entsprechenden Bayes'schen Netzwerk die Knoten für","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,C
"Versuchen Sie anhand eines großen Datensatzes medizinischer Aufzeichnungen von Patienten mit Herzerkrankungen herauszufinden, ob es möglicherweise verschiedene Gruppen solcher Patienten gibt, für die wir möglicherweise separate Behandlungen anpassen. Was ist das für ein Lernproblem?",Überwachtes Lernen,Unbeaufsichtigtes Lernen,Sowohl A als auch B),Weder A noch B),B
"Was würden Sie in PCA tun, um die gleiche Projektion wie SVD zu erhalten?",Transformieren Sie die Daten auf den Mittelwert Null,Transformieren Sie die Daten auf den Medianwert Null,Nicht möglich,Keine von diesen,A
"Aussage 1| Der Trainingsfehler des 1-Nächsten-Nachbarn-Klassifikators ist 0. Aussage 2| Wenn die Anzahl der Datenpunkte ins Unendliche wächst, nähert sich die MAP-Schätzung der MLE-Schätzung für alle möglichen Priors an. Mit anderen Worten: Bei genügend Daten ist die Wahl des Priors irrelevant.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,C
"Bei der Durchführung der Regression der kleinsten Quadrate mit Regularisierung (vorausgesetzt, dass die Optimierung exakt durchgeführt werden kann) erhöht die Erhöhung des Werts des Regularisierungsparameters λ den Testfehler.",wird den Trainingsfehler niemals verringern.,wird den Trainingsfehler niemals erhöhen.,wird den Testfehler niemals verringern.,wird nie zunehmen,A
"Welche der folgenden Aussagen beschreibt am besten, was diskriminierende Ansätze zu modellieren versuchen? (w sind die Parameter im Modell)","p(y|x, w)","p(y, x)","p(w|x, w)",Nichts des oben Genannten,A
"Aussage 1| Die CIFAR-10-Klassifizierungsleistung für Faltungs-Neuronale Netze kann 95 % überschreiten. Aussage 2| Ensembles neuronaler Netze verbessern die Klassifizierungsgenauigkeit nicht, da die von ihnen gelernten Darstellungen stark korreliert sind.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,C
In welchem ​​der folgenden Punkte wären Bayesianer und Frequentisten anderer Meinung?,Die Verwendung eines nicht-Gaußschen Rauschmodells in der probabilistischen Regression.,Die Verwendung probabilistischer Modellierung für die Regression.,Die Verwendung von A-priori-Verteilungen der Parameter in einem probabilistischen Modell.,Die Verwendung von Klassenprioren in der Gaußschen Diskriminanzanalyse.,C
"Aussage 1| Die BLEU-Metrik verwendet Präzision, während die ROGUE-Metrik Rückruf verwendet. Aussage 2| Hidden-Markov-Modelle wurden häufig zur Modellierung englischer Sätze verwendet.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
Aussage 1| ImageNet verfügt über Bilder in verschiedenen Auflösungen. Aussage 2| Caltech-101 hat mehr Bilder als ImageNet.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,C
Welche der folgenden Methoden eignet sich besser für die Funktionsauswahl?,Grat,Lasso,sowohl A als auch B),weder A noch B),B
"Angenommen, Sie erhalten einen EM-Algorithmus, der Maximum-Likelihood-Schätzungen für ein Modell mit latenten Variablen findet. Sie werden aufgefordert, den Algorithmus so zu ändern, dass er stattdessen MAP-Schätzungen findet. Welchen Schritt oder welche Schritte müssen Sie ändern?",Erwartung,Maximierung,Keine Änderung erforderlich,Beide,B
Welche dieser Strukturannahmen hat für einen Gaußschen Bayes-Klassifikator den größten Einfluss auf den Kompromiss zwischen Unteranpassung und Überanpassung:,Ob wir die Klassenzentren durch Maximum Likelihood oder Gradient Descent lernen,Ob wir von Kovarianzmatrizen voller Klassen oder von Kovarianzmatrizen diagonaler Klassen ausgehen,"Ob wir gleiche Klassenprioris oder Priors haben, die aus den Daten geschätzt werden","Ob wir zulassen, dass Klassen unterschiedliche Mittelwertvektoren haben, oder ob wir sie zwingen, denselben Mittelwertvektor zu verwenden",B
"Aussage 1| Für zwei beliebige Variablen x und y mit der gemeinsamen Verteilung p(x, y) gilt immer H[x, y] ≥ H[x] + H[y], wobei H die Entropiefunktion ist. Aussage 2| Bei einigen gerichteten Graphen verringert die Moralisierung die Anzahl der im Graphen vorhandenen Kanten.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,B
Was ist KEIN überwachtes Lernen?,PCA,Entscheidungsbaum,Lineare Regression,Naiver Bayesianer,A
Aussage 1| Die Konvergenz eines neuronalen Netzwerks hängt von der Lernrate ab. Aussage 2| Dropout multipliziert zufällig ausgewählte Aktivierungswerte mit Null.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Welche der folgenden Variablen ist gleich P(A, B, C) bei gegebenen booleschen Zufallsvariablen A, B und C und zwischen denen keine Unabhängigkeits- oder bedingte Unabhängigkeitsannahmen vorliegen?",P(A | B) * P(B | C) * P(C | A),"P(C | A, B) * P(A) * P(B)","P(A, B | C) * P(C)","P(A | B, C) * P(B | A, C) * P(C | A, B)",C
Welche der folgenden Aufgaben lässt sich am besten mit Clustering lösen?,Vorhersage der Niederschlagsmenge anhand verschiedener Hinweise,Erkennung betrügerischer Kreditkartentransaktionen,"Einem Roboter beibringen, ein Labyrinth zu lösen",Alle oben genannten,B
"Nachdem Sie bei der linearen Regression eine Regularisierungsstrafe angewendet haben, stellen Sie fest, dass einige der Koeffizienten von w auf Null gesetzt sind. Welche der folgenden Strafen könnten verhängt worden sein?",L0-Norm,L1-Norm,L2-Norm,entweder a oder B),D
"A und B sind zwei Ereignisse. Wenn P(A, B) abnimmt, während P(A) zunimmt, welche der folgenden Aussagen ist wahr?",P(A|B) nimmt ab,P(B|A) nimmt ab,P(B) nimmt ab,Alles von oben,B
"Aussage 1| Gehen wir beim Erlernen eines HMM für einen festen Satz von Beobachtungen davon aus, dass wir die wahre Anzahl der verborgenen Zustände nicht kennen (was häufig der Fall ist). Wir können die Wahrscheinlichkeit der Trainingsdaten jederzeit erhöhen, indem wir mehr verborgene Zustände zulassen. Aussage 2| Kollaboratives Filtern ist häufig ein nützliches Modell zur Modellierung der Filmpräferenzen der Benutzer.","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
"Sie trainieren ein lineares Regressionsmodell für eine einfache Schätzaufgabe und stellen fest, dass das Modell zu stark an die Daten angepasst ist. Sie beschließen, eine $\ell_2$-Regularisierung hinzuzufügen, um die Gewichte zu bestrafen. Was passiert mit der Verzerrung und Varianz des Modells, wenn Sie den Regularisierungskoeffizienten $\ell_2$ erhöhen?",Bias-Erhöhung; Varianzerhöhung,Bias-Erhöhung; Varianzabnahme,Bias-Abnahme; Varianzerhöhung,Bias-Abnahme; Varianzabnahme,B
"Welche PyTorch 1.8-Befehle erzeugen eine $10\times 5$ Gaußsche Matrix mit jedem Eintrag i.i.d. abgetastet aus $\mathcal{N}(\mu=5,\sigma^2=16)$ und einer $10\times 10$ einheitlichen Matrix mit jedem Eintrag i.i.d. entnommen aus $U[-1,1)$?","\texttt{5 + Torch.randn(10,5) * 16} ; \texttt{torch.rand(10,10,low=-1,high=1)}","\texttt{5 + Torch.randn(10,5) * 16} ; \texttt{(torch.rand(10,10) - 0,5) / 0,5}","\texttt{5 + Torch.randn(10,5) * 4} ; \texttt{2 * Torch.rand(10,10) - 1}","\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \texttt{2 * Torch.rand(10,10) - 1}",C
Aussage 1| Der Gradient der ReLU ist Null für $x<0$ und der Sigmoidgradient $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ für alle $x$. Aussage 2| Das Sigmoid hat einen kontinuierlichen Gradienten und die ReLU hat einen diskontinuierlichen Gradienten.,"Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,A
Was ist wahr an der Batch-Normalisierung?,Nach der Anwendung der Batch-Normalisierung folgen die Aktivierungen der Ebene einer Standard-Gauß-Verteilung.,"Der Bias-Parameter affiner Schichten wird überflüssig, wenn unmittelbar darauf eine Batch-Normalisierungsschicht folgt.",Bei Verwendung der Batch-Normalisierung muss die Standardgewichtsinitialisierung geändert werden.,Die Batch-Normalisierung entspricht der Layer-Normalisierung für Faltungs-Neuronale Netze.,B
"Angenommen, wir haben die folgende Zielfunktion: $\argmin_{w} \frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\gamma \norm{w}^2_2$ Wie groß ist der Gradient von $\frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\lambda \norm{w}^2_2$ in Bezug auf $w$?",$\nabla_w f(w) = (X^\top X + \lambda I)w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + (\lambda+1) w$,C
Welche der folgenden Aussagen trifft auf einen Faltungskern zu?,Das Falten eines Bildes mit $\begin{bmatrix}1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ würde das Bild nicht verändern,Das Falten eines Bildes mit $\begin{bmatrix}0 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ würde das Bild nicht verändern,Das Falten eines Bildes mit $\begin{bmatrix}1 & 1 & 1\\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}$ würde das Bild nicht verändern,Das Falten eines Bildes mit $\begin{bmatrix}0 & 0 & 0\\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ würde das Bild nicht verändern,B
Welche der folgenden Aussagen ist falsch?,"Semantische Segmentierungsmodelle sagen die Klasse jedes Pixels voraus, während Mehrklassen-Bildklassifikatoren die Klasse des gesamten Bildes vorhersagen.",Ein Begrenzungsrahmen mit einem IoU (Schnittpunkt über der Vereinigung) von $96\%$ würde wahrscheinlich als richtig positiv betrachtet werden.,"Wenn ein vorhergesagter Begrenzungsrahmen keinem Objekt in der Szene entspricht, wird dies als falsch positiv betrachtet.",Ein Begrenzungsrahmen mit einem IoU (Schnittpunkt über der Vereinigung) von $3\%$ würde wahrscheinlich als falsch negativ betrachtet werden.,D
Welche der folgenden Aussagen ist falsch?,"Das folgende vollständig zusammenhängende Netzwerk ohne Aktivierungsfunktionen ist linear: $g_3(g_2(g_1(x)))$, wobei $g_i(x) = W_i x$ und $W_i$ Matrizen sind.","Leaky ReLU $\max\{0.01x,x\}$ ist konvex.",Eine Kombination von ReLUs wie $ReLU(x) - ReLU(x-1)$ ist konvex.,Der Verlust $\log \sigma(x)= -\log(1+e^{-x})$ ist konkav,C
"Wir trainieren ein vollständig verbundenes Netzwerk mit zwei verborgenen Schichten, um Immobilienpreise vorherzusagen. Die Eingaben sind 100-Dollar-dimensional und weisen mehrere Merkmale auf, wie z. B. die Anzahl der Quadratfuß, das mittlere Familieneinkommen usw. Die erste verborgene Ebene weist Aktivierungen im Wert von 1000 Dollar auf. Die zweite verborgene Ebene hat Aktivierungen im Wert von 10 $. Die Ausgabe ist ein Skalar, der den Hauspreis darstellt. Angenommen, ein Vanilla-Netzwerk mit affinen Transformationen und ohne Batch-Normalisierung und ohne lernbare Parameter in der Aktivierungsfunktion, wie viele Parameter hat dieses Netzwerk?",111021,110010,111110,110011,A
"Aussage 1| Die Ableitung des Sigmoids $\sigma(x)=(1+e^{-x})^{-1}$ nach $x$ ist gleich $\text{Var}(B)$, wobei $B \sim \text{Bern}(\sigma(x))$ ist eine Bernoulli-Zufallsvariable. Aussage 2| Wenn Sie die Bias-Parameter in jeder Schicht des neuronalen Netzwerks auf 0 setzen, ändert sich der Bias-Varianz-Kompromiss, sodass die Varianz des Modells zunimmt und die Bias des Modells abnimmt","Wahr, wahr","False, False",Wahr falsch,Falsch Richtig,C
