البيان 1 | مقدر الانحدار الخطي لديه أصغر تباين بين جميع المقدرات غير المتحيزة. البيان 2 | دائمًا ما تكون المعاملات α المخصصة للمصنفات التي تم تجميعها بواسطة AdaBoost غير سالبة.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,D
البيان 1 | RoBERTa prrains على جسم يقارب 10x أكبر من الجسم BERT الذي تم اختباره مسبقًا. البيان 2 | يستخدم ResNeXts في عام 2018 عادةً وظائف تنشيط tanh.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,C
البيان 1 | تقدم آلات المتجهات الداعمة ، مثل نماذج الانحدار اللوجستي ، توزيعًا احتماليًا للتسميات المحتملة في ضوء مثال الإدخال. البيان 2 | نتوقع أن تظل متجهات الدعم كما هي بشكل عام عندما ننتقل من نواة خطية إلى نواة متعددة الحدود ذات رتبة أعلى.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
تتضمن مشكلة التعلم الآلي أربع سمات بالإضافة إلى فصل دراسي. تحتوي السمات على 3 و 2 و 2 و 2 قيم محتملة لكل منها. يحتوي الفصل على 3 قيم محتملة. كم عدد الأمثلة المختلفة الممكنة الموجودة؟,12,24,48,72,D
اعتبارًا من عام 2020 ، ما هي الهندسة المعمارية الأفضل لتصنيف الصور عالية الدقة؟,الشبكات التلافيفية,شبكات الرسم البياني,شبكات متصلة بالكامل,شبكات RBF,A
البيان 1 | ستزداد احتمالية تسجيل البيانات دائمًا من خلال التكرارات المتتالية لخوارزمية تعظيم التوقعات. البيان 2 | أحد عيوب Q-Learning هو أنه لا يمكن استخدامه إلا عندما يكون لدى المتعلم معرفة مسبقة عن كيفية تأثير أفعاله على بيئته.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
لنفترض أننا قد حسبنا تدرج دالة التكلفة لدينا وقمنا بتخزينها في المتجه g. ما تكلفة تحديث نزول التدرج الواحد بالنظر إلى التدرج؟,يا (د),على),يا (ND),يا (ND ^ 2),A
البيان 1 | بالنسبة للمتغير العشوائي المستمر x ودالة التوزيع الاحتمالي الخاصة به p (x) ، فإنه يحمل 0 ≤ p (x) ≤ 1 لكل x. البيان 2 | يتم تعلم شجرة القرار عن طريق تقليل اكتساب المعلومات.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
ضع في اعتبارك شبكة بايز الواردة أدناه. كم عدد المعلمات المستقلة المطلوبة لشبكة Bayesian Network H -> U <- P <- W؟,2,4,8,16,C
نظرًا لأن عدد أمثلة التدريب يذهب إلى ما لا نهاية ، فإن نموذجك الذي تم تدريبه على تلك البيانات سيكون له:,تباين أقل,تباين أعلى,نفس التباين,لا شيء مما بالأعلى,A
البيان 1 | يمكن لمجموعة كل المستطيلات في المستوى ثنائي الأبعاد (التي تتضمن مستطيلات غير محورية) تحطيم مجموعة من 5 نقاط. البيان 2 | البعد VC لمصنف k-Nearest Neighbor عندما تكون k = 1 لانهائية.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
_ يشير إلى نموذج لا يمكنه نمذجة بيانات التدريب أو التعميم على بيانات جديدة.,تركيب جيد,overfitting,غير مناسب,كل ما ورداعلاه,C
البيان 1 | يمكن أن تكون درجة F1 مفيدة بشكل خاص لمجموعات البيانات ذات الاختلال العالي في الفئة. البيان 2 | تعد المنطقة الواقعة أسفل منحنى ROC أحد المقاييس الرئيسية المستخدمة لتقييم أجهزة الكشف عن الشذوذ.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
البيان 1 | تتعلم خوارزمية الانتشار العكسي شبكة عصبية مثالية عالميًا مع طبقات مخفية. البيان 2 | يجب أن يكون بُعد VC للخط 2 على الأكثر ، حيث يمكنني العثور على حالة واحدة على الأقل من 3 نقاط لا يمكن تحطيمها بأي خط.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
الانتروبيا العالية تعني أن الأقسام في التصنيف هي,نقي,ليس نقي,مفيد,عديم الفائدة,B
البيان 1 | تُستخدم تسوية الطبقة في ورق ResNet الأصلي ، وليس تطبيع الدُفعات. البيان 2 | تستخدم DCGANs الاهتمام الذاتي لتحقيق الاستقرار في التدريب.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
عند بناء نموذج انحدار خطي لمجموعة بيانات معينة ، يمكنك ملاحظة معامل إحدى الميزات التي لها قيمة سالبة عالية نسبيًا. هذا يشير إلى أن,هذه الميزة لها تأثير قوي على النموذج (يجب الاحتفاظ بها),هذه الميزة ليس لها تأثير قوي على النموذج (يجب تجاهلها),لا يمكن التعليق على أهمية هذه الميزة بدون معلومات إضافية,لا شيء يمكن تحديده.,C
بالنسبة للشبكة العصبية ، أي من هذه الافتراضات الهيكلية هو الأكثر تأثيرًا على المقايضة بين عدم الملائمة (أي نموذج التحيز العالي) والتركيب الزائد (أي نموذج التباين العالي):,عدد العقد المخفية,معدل التعلم,الاختيار الأولي للأوزان,استخدام مدخلات وحدة ذات المدى الثابت,A
بالنسبة إلى الانحدار متعدد الحدود ، أي من هذه الافتراضات الهيكلية هو الأكثر تأثيرًا على المفاضلة بين المقايضة غير المناسبة والتركيب الزائد:,الدرجة متعددة الحدود,سواء كنا نتعلم الأوزان عن طريق انعكاس المصفوفة أو نزول التدرج,التباين المفترض للضوضاء الغاوسية,استخدام مدخلات وحدة ذات المدى الثابت,A
البيان 1 | اعتبارًا من عام 2020 ، حققت بعض الطرز دقة تزيد عن 98٪ في CIFAR-10. البيان 2 | لم يتم تحسين شبكات ResNets الأصلية باستخدام مُحسِّن Adam.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
خوارزمية K- يعني:,يتطلب أن لا يكون حجم مساحة الميزة أكبر من عدد العينات,لديه أصغر قيمة لوظيفة الهدف عندما يكون K = 1,يقلل التباين داخل الفئة لعدد معين من المجموعات,يتقارب مع المستوى الأمثل العالمي إذا وفقط إذا تم اختيار الوسائل الأولية باعتبارها بعض العينات نفسها,C
البيان 1 | تحتوي VGGNets على نوى تلافيفية ذات عرض وارتفاع أصغر من نوى الطبقة الأولى من AlexNet. البيان 2 | تم تقديم إجراءات تهيئة الوزن المعتمدة على البيانات قبل تسوية الدُفعات.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
ما هي رتبة المصفوفة التالية؟ أ = [[1 ، 1 ، 1] ، [1 ، 1 ، 1] ، [1 ، 1 ، 1]],0,1,2,3,B
البيان 1 | يمكن استخدام تقدير الكثافة (باستخدام مقدر كثافة النواة مثلاً) لإجراء التصنيف. البيان 2 | التطابق بين الانحدار اللوجستي و Gaussian Naive Bayes (مع التغاير في فئة الهوية) يعني أن هناك تطابق واحد إلى واحد بين معلمات المصنفين.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,C
لنفترض أننا نرغب في إجراء التجميع على البيانات المكانية مثل المواقع الهندسية للمنازل. نرغب في إنتاج مجموعات من العديد من الأحجام والأشكال المختلفة. أي من الطرق التالية هو الأنسب؟,أشجار القرار,التجميع على أساس الكثافة,التجميع القائم على النموذج,K- يعني التجميع,B
البيان 1 | في AdaBoost ، ترتفع أوزان الأمثلة المصنفة بشكل خاطئ بنفس عامل الضرب. البيان 2 | في AdaBoost ، خطأ التدريب الموزون e_t لمصنف tth الضعيف على بيانات التدريب ذات الأوزان D_t يميل إلى الزيادة كدالة لـ t.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
غالبًا ما تكون تقديرات MLE غير مرغوب فيها بسبب,هم متحيزون,لديهم تباين كبير,هم ليسوا مقدرين متسقين,لا شيء مما بالأعلى,B
التعقيد الحسابي لنسب التدرج هو ،,خطي في د,خطي في N.,كثير الحدود في د,حسب عدد التكرارات,C
يساعد حساب متوسط ​​ناتج أشجار القرار المتعددة _.,زيادة التحيز,تقليل التحيز,زيادة التباين,تقليل التباين,D
قد يختلف النموذج الذي تم الحصول عليه من خلال تطبيق الانحدار الخطي على مجموعة فرعية محددة من الميزات عن النموذج الذي تم الحصول عليه في نهاية عملية تحديد المجموعة الفرعية أثناء,أفضل اختيار مجموعة فرعية,اختيار متدرج للأمام,اختيار المرحلة الحكيمة إلى الأمام,كل ما ورداعلاه,C
الشبكات العصبية:,تحسين وظيفة الهدف المحدبة,لا يمكن تدريبه إلا باستخدام النسب المتدرج العشوائي,يمكن استخدام مزيج من وظائف التنشيط المختلفة,لا شيء مما بالأعلى,C
"لنفترض أن معدل حدوث المرض D يبلغ حوالي 5 حالات لكل 100 شخص (أي P (D) = 0.05). لنفترض أن المتغير العشوائي المنطقي D يعني أن المريض ""يعاني من المرض D"" ودع المتغير العشوائي المنطقي TP يقف لعبارة ""الاختبارات إيجابية"". من المعروف أن الاختبارات الخاصة بالمرض D دقيقة للغاية بمعنى أن احتمال الاختبار الإيجابي عند الإصابة بالمرض هو 0.99 ، واحتمال الاختبار السلبي عندما لا يكون لديك المرض هو 0.97. ما هو P (TP) ، الاحتمال السابق للاختبار الإيجابي.",٠.٠٣٦٨,٠.٤٧٣,٠.٠٧٨,لا شيء مما بالأعلى,C
البيان 1 | بعد التعيين في مساحة الميزة Q من خلال وظيفة النواة ذات الأساس الشعاعي ، قد تتمكن 1-NN باستخدام مسافة الإقليدية غير الموزونة من تحقيق أداء تصنيف أفضل من المساحة الأصلية (على الرغم من أننا لا نستطيع ضمان ذلك). البيان 2 | يكون بُعد VC لجهاز Perceptron أصغر من بُعد VC لجهاز SVM خطي بسيط.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
عيب شبكة البحث هو,لا يمكن تطبيقه على الوظائف غير القابلة للتفاضل.,لا يمكن تطبيقه على الوظائف غير المستمرة.,من الصعب تنفيذها.,إنه يعمل ببطء إلى حد معقول بالنسبة للانحدار الخطي المتعدد.,D
إن التنبؤ بكمية هطول الأمطار في منطقة ما بناءً على إشارات مختلفة يمثل مشكلة ______.,التعلم تحت الإشراف,تعليم غير مشرف عليه,تجمع,لا شيء مما بالأعلى,A
أي من الجمل التالية هي FALSE بخصوص الانحدار؟,يتعلق المدخلات بالمخرجات.,يتم استخدامه للتنبؤ.,يمكن استخدامه للتفسير.,يكتشف العلاقات السببية,D
أي مما يلي هو السبب الرئيسي لتقليم شجرة القرار؟,لتوفير وقت الحوسبة أثناء الاختبار,لتوفير مساحة لتخزين شجرة القرار,لجعل خطأ مجموعة التدريب أصغر,لتجنب فرط تجهيز مجموعة التدريب,D
البيان 1 | يعادل مقدر كثافة النواة أداء انحدار النواة مع القيمة Yi = 1 / n عند كل نقطة Xi في مجموعة البيانات الأصلية. البيان 2 | يمكن أن يكون عمق شجرة القرار المكتسبة أكبر من عدد أمثلة التدريب المستخدمة لإنشاء الشجرة.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
افترض أن النموذج الخاص بك هو أكثر من اللازم. أي مما يلي ليس طريقة صالحة لمحاولة تقليل فرط التجهيز؟,زيادة كمية بيانات التدريب.,تحسين خوارزمية التحسين المستخدمة لتقليل الأخطاء.,تقليل تعقيد النموذج.,تقليل الضوضاء في بيانات التدريب.,B
البيان 1 | تُستخدم وظيفة softmax بشكل شائع في الانحدار اللوجستي متعدد الفئات. البيان 2 | تؤثر درجة حرارة توزيع softmax غير المنتظم على إنتروبياها.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
أي مما يلي يعتبر صحيحًا فيما يتعلق بـ SVM؟,بالنسبة لنقاط البيانات ثنائية الأبعاد ، فإن المستوى الفائق الفاصل الذي تم تعلمه بواسطة SVM الخطي سيكون خطًا مستقيمًا.,من الناحية النظرية ، لا يمكن لـ SVM Gaussian kernel نمذجة أي معقد يفصل المستوي الفائق.,لكل دالة نواة مستخدمة في SVM ، يمكن للمرء الحصول على توسع أساس مغلق بشكل مكافئ.,لا يعد التجهيز الزائد في SVM دالة لعدد متجهات الدعم.,A
أي مما يلي هو الاحتمال المشترك لـ H و U و P و W الموصوف بواسطة شبكة Bayesian Network H -> U <- P <- W؟ [ملاحظة: كناتج للاحتمالات الشرطية],الفوسفور (H ، U ، P ، W) = P (H) * P (W) * P (P) * P (U),الفوسفور (H ، U ، P ، W) = P (H) * P (W) * P (P | W) * P (W | H ، P),الفوسفور (H ، U ، P ، W) = P (H) * P (W) * P (P | W) * P (U | H ، P),لا شيء مما بالأعلى,C
البيان 1 | نظرًا لأن بُعد VC لـ SVM مع نواة قاعدة شعاعية لا نهائي ، يجب أن يكون SVM أسوأ من SVM مع نواة متعددة الحدود ذات بُعد VC محدود. البيان 2 | الشبكة العصبية المكونة من طبقتين مع وظائف التنشيط الخطي هي في الأساس مجموعة مرجحة من الفواصل الخطية ، مدربة على مجموعة بيانات معينة ؛ وجدت خوارزمية التعزيز المبنية على الفواصل الخطية أيضًا مجموعة من الفواصل الخطية ، وبالتالي فإن هاتين الخوارزميتين ستعطيان نفس النتيجة.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
البيان 1 | خوارزمية ID3 مضمونة للعثور على شجرة القرار الأمثل. البيان 2 | ضع في اعتبارك توزيع احتمالية مستمر بكثافة f () غير صفرية في كل مكان. احتمال قيمة x يساوي f (x).,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
بالنظر إلى الشبكة العصبية مع عقد إدخال N ، لا توجد طبقات مخفية ، عقدة إخراج واحدة ، مع وظائف Entropy Loss و Sigmoid Activation ، أي من الخوارزميات التالية (مع المعلمات الفائقة المناسبة والتهيئة) يمكن استخدامها للعثور على الأمثل العالمي؟,الانحدار العشوائي,نزول متدرج دفعة صغيرة,نزول دفعة متدرجة,كل ما ورداعلاه,D
إضافة المزيد من وظائف الأساس في نموذج خطي ، اختر الخيار الأكثر احتمالاً:,يقلل من تحيز النموذج,يقلل تقدير التحيز,يقلل التباين,لا يؤثر على التحيز والتباين,A
ضع في اعتبارك شبكة بايز الواردة أدناه. كم عدد المعلمات المستقلة التي سنحتاجها إذا لم نضع افتراضات حول الاستقلال أو الاستقلال الشرطي H -> U <- P <- W؟,3,4,7,15,D
مصطلح آخر للكشف عن خارج التوزيع هو؟,إكتشاف عيب خلقي,كشف من فئة واحدة,متانة عدم تطابق اختبار القطار,الكشف عن الخلفية,A
البيان 1 | نتعلم المصنف f من خلال تعزيز المتعلمين الضعفاء h. الشكل الوظيفي لحدود القرار f هو نفسه h ، ولكن مع معلمات مختلفة. (على سبيل المثال ، إذا كان h مصنفًا خطيًا ، فإن f أيضًا مصنف خطي). البيان 2 | يمكن استخدام التحقق المتقاطع لتحديد عدد التكرارات في التعزيز ؛ قد يساعد هذا الإجراء في تقليل فرط التجهيز.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,D
البيان 1 | تم إدخال شبكات الطرق السريعة بعد ResNets وتجنب تجمع max لصالح التلافيف. البيان 2 | عادة ما تكلف DenseNets ذاكرة أكثر من ResNets.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,D
إذا كان N هو عدد المثيلات في مجموعة بيانات التدريب ، فإن أقرب جيران لديهم وقت تشغيل تصنيف,يا (1),على),O (تسجيل N),O (N ^ 2),B
البيان 1 | إن شبكات ResNets والمحولات الأصلية هي شبكات عصبية مغذية. البيان 2 | تستخدم المحولات الأصلية الاهتمام الذاتي ، لكن شبكة ResNet الأصلية لا تستخدم ذلك.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
البيان 1 | RELUs ليست رتيبة ، ولكن sigmoids رتيبة. البيان 2 | الشبكات العصبية المدربة على الانحدار المتدرج مع الاحتمالية العالية تتلاقى مع المستوى العالمي الأمثل.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,D
الناتج العددي للعقدة السينية في الشبكة العصبية:,غير محدود ، يشمل جميع الأعداد الحقيقية.,غير محدود ، يشمل جميع الأعداد الصحيحة.,يحده بين 0 و 1.,يحده بين -1 و 1.,C
أي مما يلي يمكن استخدامه فقط عندما تكون بيانات التدريب قابلة للفصل خطيًا؟,الخطي ذو الهامش الثابت SVM.,الانحدار اللوجستي الخطي.,الهامش الخطي الناعم SVM.,طريقة النقطه الوسطى.,A
أي مما يلي هي خوارزميات التجميع المكاني؟,التجميع القائم على التقسيم,K- يعني التجميع,التجميع على أساس الشبكة,كل ما ورداعلاه,D
البيان 1 | الحدود القصوى لقرار الهامش التي تدعم بناء آلات المتجه لها أدنى خطأ تعميم بين جميع المصنفات الخطية. البيان 2 | يمكن من حيث المبدأ إعادة إنتاج أي حدود قرار نحصل عليها من نموذج توليدي مع توزيعات غاوسية مشروطة للفئة باستخدام SVM ونواة متعددة الحدود بدرجة أقل من أو تساوي ثلاثة.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,D
البيان 1 | يميل تنظيم L2 للنماذج الخطية إلى جعل النماذج أكثر نثرًا من تنظيم L1. البيان 2 | يمكن العثور على الاتصالات المتبقية في ResNets والمحولات.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,D
لنفترض أننا نرغب في حساب P (H | E ، F) وليس لدينا معلومات استقلالية مشروطة. أي من مجموعات الأرقام التالية كافية للحساب؟,الفوسفور (ه ، ف) ، ف (ح) ، ف (ه | ح) ، ف (ف | ح),الفوسفور (ه ، ف) ، ف (ح) ، ف (ه ، ف | ح),الفوسفور (ح) ، الفوسفور (ه | ح) ، ف (و | ح),الفوسفور (ه ، ف) ، ف (ه | ح) ، ف (ف | ح),B
أي مما يلي يمنع فرط التجهيز عند إجراء التعبئة؟,استخدام أخذ العينات مع الاستبدال كأسلوب لأخذ العينات,استخدام المصنفات الضعيفة,استخدام خوارزميات التصنيف غير المعرضة للإفراط في التجهيز,تم إجراء عملية التحقق من الصحة على كل مصنف تم تدريبه,B
البيان 1 | يقوم PCA و Spectral Clustering (مثل Andrew Ng's) بتنفيذ eigendecomposition على مصفوفتين مختلفتين. ومع ذلك ، فإن حجم هاتين المصفوفتين هو نفسه. البيان 2 | نظرًا لأن التصنيف هو حالة خاصة من الانحدار ، فإن الانحدار اللوجستي هو حالة خاصة من الانحدار الخطي.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
البيان 1 | احتوى The Stanford Sentiment Treebank على مراجعات للأفلام ، وليس مراجعات للكتب. البيان 2 | تم استخدام Penn Treebank لنمذجة اللغة.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
ما هي أبعاد الفضاء الفارغ للمصفوفة التالية؟ A = [[3، 2، −9]، [6، −4، 18]، [12، 8، −36]],0,1,2,3,C
ما هي نواقل الدعم؟,الأمثلة الأبعد عن حدود القرار.,الأمثلة الوحيدة اللازمة لحساب f (x) في SVM.,مركز البيانات.,جميع الأمثلة التي لها وزن غير صفري αk في SVM.,B
البيان 1 | لم تتم تهيئة معلمات Word2Vec باستخدام آلة Boltzman المقيدة. البيان 2 | وظيفة tanh هي وظيفة تنشيط غير خطية.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
إذا زاد خسارتك في التدريب مع زيادة عدد الفترات ، فأي مما يلي يمكن أن يمثل مشكلة محتملة في عملية التعلم؟,التنظيم منخفض جدًا والنموذج مفرط في التجهيز,التنظيم مرتفع للغاية والنموذج غير ملائم,حجم الخطوة كبير جدًا,حجم الخطوة صغير جدًا,C
"لنفترض أن معدل حدوث المرض D يبلغ حوالي 5 حالات لكل 100 شخص (أي P (D) = 0.05). لنفترض أن المتغير العشوائي المنطقي D يعني أن المريض ""يعاني من المرض D"" ودع المتغير العشوائي المنطقي TP يقف لعبارة ""الاختبارات إيجابية"". من المعروف أن الاختبارات الخاصة بالمرض D دقيقة للغاية بمعنى أن احتمال الاختبار الإيجابي عند الإصابة بالمرض هو 0.99 ، واحتمال الاختبار السلبي عندما لا يكون لديك المرض هو 0.97. ما هو الاحتمال الخلفي للإصابة بالمرض D عندما يكون الاختبار إيجابيًا؟",٠.٠٤٩٥,٠.٠٧٨,٠.٦٣٥,٠.صح,C
البيان 1 | تفترض نتائج التعلم الآلي التقليدية أن مجموعات التدريب والاختبار مستقلة وموزعة بشكل متماثل. البيان 2 | في عام 2017 ، تم اختبار نماذج COCO عادةً على ImageNet.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
البيان 1 | لا تخبرنا قيم الهوامش التي حصلت عليها نواتان مختلفتان K1 (x، x0) و K2 (x، x0) في نفس مجموعة التدريب عن المصنف الذي سيعمل بشكل أفضل في مجموعة الاختبار. البيان 2 | وظيفة تنشيط BERT هي GELU.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
أي مما يلي عبارة عن خوارزمية التجميع في التعلم الآلي؟,زيادة التوقعات,عربة التسوق,Gaussian Naïve Bayes,بداهة,A
لقد انتهيت للتو من تدريب شجرة قرار لتصنيف الرسائل غير المرغوب فيها ، وهي تحصل على أداء سيئ بشكل غير طبيعي في كل من مجموعات التدريب والاختبار. أنت تعلم أن تطبيقك لا يحتوي على أخطاء ، فما سبب المشكلة؟,أشجار قرارك ضحلة جدًا.,تحتاج إلى زيادة معدل التعلم.,أنت تفرط في التجهيز.,لا شيء مما بالأعلى.,A
K- أضعاف عبر التحقق من الصحة,خطي في K.,تربيعي في K.,مكعب في K.,أسي في K.,A
البيان 1 | عادةً ما يتم تدريب الشبكات العصبية ذات النطاق الصناعي على وحدات المعالجة المركزية (CPU) ، وليس وحدات معالجة الرسومات (GPU). البيان 2 | يحتوي نموذج ResNet-50 على أكثر من مليار معلمة.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
بالنظر إلى متغيرين عشوائيين منطقيين ، A و B ، حيث P (A) = 1/2 ، P (B) = 1/3 ، و P (A | ¬B) = 1/4 ، ما هو P (A | B) ؟,1/6,1/4,3/4,1,D
ترتبط المخاطر الوجودية التي يشكلها الذكاء الاصطناعي بشكل شائع بأي من الأساتذة التاليين؟,ناندو دي فريتاس,داخل Y Ann l ECU,ستيوارت راسل,جيتندرا مالك,C
البيان 1 | يؤدي تعظيم احتمالية نموذج الانحدار اللوجستي إلى تحقيق العديد من القيم المثلى المحلية. البيان 2 | لا يمكن لأي مصنف أن يفعل أفضل من مصنف Bayes الساذج إذا كان توزيع البيانات معروفًا.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
بالنسبة إلى Kernel Regression ، أي من هذه الافتراضات الهيكلية هو الأكثر تأثيرًا على المقايضة بين التجهيز الناقص والتجهيز الزائد:,ما إذا كانت وظيفة kernel هي Gaussian مقابل المثلث مقابل شكل مربع,ما إذا كنا نستخدم مقاييس الإقليدية مقابل L1 مقابل L∞,عرض النواة,أقصى ارتفاع لدالة النواة,C
البيان 1 | تضمن خوارزمية التعلم SVM العثور على الفرضية المثلى عالميًا فيما يتعلق بوظيفة الكائن الخاصة بها. البيان 2 | بعد تعيينه في مساحة الميزة Q من خلال وظيفة kernel ذات الأساس الشعاعي ، قد يتمكن Perceptron من تحقيق أداء تصنيف أفضل مما كان عليه في مساحته الأصلية (على الرغم من أننا لا نستطيع ضمان ذلك).,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
بالنسبة لمصنف Gaussian Bayes ، أي من هذه الافتراضات الهيكلية هو الأكثر تأثيرًا على المقايضة بين المقايضة غير المناسبة والتركيب الزائد:,سواء كنا نتعلم مراكز الفصل عن طريق الحد الأقصى من الاحتمالية أو نزول التدرج,سواء افترضنا مصفوفات التغاير للفئة الكاملة أو مصفوفات التغاير للفئة القطرية,ما إذا كان لدينا درجات متكافئة أو سابقة مقدرة من البيانات.,سواء كنا نسمح للفئات بأن يكون لها متجهات متوسطة مختلفة أو نجبرهم على مشاركة نفس المتجه المتوسط,B
البيان 1 | تزداد احتمالية التخصيص عندما تكون مجموعة بيانات التدريب صغيرة. البيان 2 | تزداد احتمالية التخصيص عندما تكون مساحة الفرضية صغيرة.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,D
البيان 1 | إلى جانب EM ، يمكن استخدام النسب المتدرج لأداء الاستدلال أو التعلم على نموذج خليط غاوسي. البيان 2 | بافتراض عدد ثابت من السمات ، يمكن التعرف على مصنف Bayes الأمثل القائم على Gaussian في الوقت الخطي في عدد السجلات في مجموعة البيانات.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
البيان 1 | في شبكة بايز ، تكون نتائج الاستدلال لخوارزمية شجرة الوصلات هي نفسها نتائج الاستدلال للتخلص المتغير. البيان 2 | إذا كان هناك متغيران عشوائيان X و Y مستقلان بشكل مشروط بالنظر إلى متغير عشوائي آخر Z ، فعندئذٍ في شبكة Bayesian المقابلة ، تكون العقدتان X و Y مفصولة عن d مع إعطاء Z.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,C
بالنظر إلى مجموعة بيانات كبيرة من السجلات الطبية للمرضى الذين يعانون من أمراض القلب ، حاول معرفة ما إذا كانت هناك مجموعات مختلفة من هؤلاء المرضى قد نخصص لها علاجات منفصلة. أي نوع من مشكلة التعلم هذه؟,التعلم تحت الإشراف,تعليم غير مشرف عليه,كلا (أ) و (ب),لا أ ولا حتى ب),B
ماذا ستفعل في PCA للحصول على نفس الإسقاط مثل SVD؟,تحويل البيانات إلى صفر يعني,تحويل البيانات إلى صفر متوسط,غير ممكن,أيا من هذه,A
البيان 1 | خطأ تدريب 1-المصنف الجار الأقرب هو 0. العبارة 2 | نظرًا لأن عدد نقاط البيانات ينمو إلى ما لا نهاية ، يقترب تقدير MAP من تقدير MLE لجميع المقدمات المحتملة. بعبارة أخرى ، بالنظر إلى البيانات الكافية ، يكون اختيار الخيار السابق غير ذي صلة.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,C
عند القيام بانحدار المربعات الصغرى مع التنظيم (بافتراض أن التحسين يمكن أن يتم بالضبط) ، فإن زيادة قيمة معامل التنظيم خطأ الاختبار.,لن تقلل من خطأ التدريب.,لن تزيد من خطأ التدريب.,لن تقلل من خطأ الاختبار.,لن تزيد أبدا,A
أي مما يلي يصف بشكل أفضل الأساليب التمييزية التي تحاول نمذجة؟ (ث هي المعلمات في النموذج),ص (ص | س ، ث),ص (ص ، س),ص (ث | س ، ث),لا شيء مما بالأعلى,A
البيان 1 | يمكن أن يتجاوز أداء تصنيف CIFAR-10 للشبكات العصبية الالتفافية 95٪. البيان 2 | لا تعمل مجموعات الشبكات العصبية على تحسين دقة التصنيف لأن التمثيلات التي يتعلمونها مرتبطة بشكل كبير.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,C
أي من النقاط التالية قد يختلف عليها البايزيون والمتكررون؟,استخدام نموذج ضوضاء غير غاوسي في الانحدار الاحتمالي.,استخدام النمذجة الاحتمالية للانحدار.,استخدام التوزيعات السابقة على المعلمات في نموذج احتمالي.,استخدام مقدمات الفئة في التحليل التمييزي الغاوسي.,C
البيان 1 | يستخدم مقياس BLEU الدقة ، بينما يستخدم مقياس ROGUE الاسترجاع. البيان 2 | تم استخدام نماذج ماركوف المخفية بشكل متكرر لنمذجة الجمل الإنجليزية.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
البيان 1 | ImageNet لديها صور بدقة مختلفة. البيان 2 | يحتوي Caltech-101 على صور أكثر من ImageNet.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,C
أي مما يلي هو الأنسب لاختيار الميزة؟,حافة,لاسو,كلا (أ) و (ب),لا أ ولا حتى ب),B
لنفترض أنك حصلت على خوارزمية كهرومغناطيسية تجد أقصى تقديرات احتمالية لنموذج به متغيرات كامنة. يُطلب منك تعديل الخوارزمية بحيث تجد تقديرات MAP بدلاً من ذلك. ما الخطوة أو الخطوات التي تحتاج إلى تعديلها؟,توقع,تعظيم,لا حاجة للتعديل,كلاهما,B
بالنسبة لمصنف Gaussian Bayes ، أي من هذه الافتراضات الهيكلية هو الأكثر تأثيرًا على المقايضة بين المقايضة غير المناسبة والتركيب الزائد:,سواء كنا نتعلم مراكز الفصل عن طريق الحد الأقصى من الاحتمالية أو نزول التدرج,سواء افترضنا مصفوفات التغاير للفئة الكاملة أو مصفوفات التغاير للفئة القطرية,ما إذا كان لدينا درجات متكافئة أو سابقة مقدرة من البيانات,سواء كنا نسمح للفئات بأن يكون لها متجهات متوسطة مختلفة أو نجبرهم على مشاركة نفس المتجه المتوسط,B
البيان 1 | لأي متغيرين x و y لهما توزيع مشترك p (x، y) ، لدينا دائمًا H [x، y] ≥ H [x] + H [y] حيث H هي دالة إنتروبيا. البيان 2 | بالنسبة لبعض الرسوم البيانية الموجهة ، يقلل الأخلاق من عدد الحواف الموجودة في الرسم البياني.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,B
أي مما يلي لا يعتبر تعليمًا خاضعًا للإشراف؟,PCA,شجرة القرار,الانحدارالخطي,ساذج بايزي,A
البيان 1 | يعتمد تقارب الشبكة العصبية على معدل التعلم. البيان 2 | يضاعف التسرب قيم التنشيط المختارة عشوائيًا بمقدار صفر.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
أي مما يلي يساوي P (A ، B ، C) مع الأخذ في الاعتبار المتغيرات العشوائية المنطقية A و B و C ، ولا توجد افتراضات استقلالية أو استقلالية مشروطة بين أي منها؟,ف (أ | ب) * ف (ب | ج) * ف (ج | أ),ف (ج | أ ، ب) * ف (أ) * ف (ب),ف (أ ، ب | ج) * ف (ج),الفوسفور (أ | ب ، ج) * ف (ب | أ ، ج) * ف (ج | أ ، ب),C
أي من المهام التالية يمكن حلها بشكل أفضل باستخدام Clustering.,توقع كمية الأمطار بناءً على إشارات مختلفة,كشف معاملات بطاقات الائتمان الاحتيالية,تدريب إنسان آلي على حل متاهة,كل ما ورداعلاه,B
بعد تطبيق عقوبة التنظيم في الانحدار الخطي ، تجد أن بعض معاملات w قد تم صفرها. أي من العقوبات التالية ربما تم استخدامه؟,القاعدة L0,القاعدة L1,القاعدة L2,إما (أ) أو (ب),D
A و B حدثان. إذا انخفض P (A ، B) بينما زاد P (A) ، فأي مما يلي يكون صحيحًا؟,P (A | B) ينقص,P (B | A) ينقص,P (B) ينقص,كل ما سبق,B
البيان 1 | عند تعلم HMM لمجموعة ثابتة من الملاحظات ، افترض أننا لا نعرف العدد الحقيقي للحالات المخفية (وهو ما يحدث غالبًا) ، يمكننا دائمًا زيادة احتمالية بيانات التدريب من خلال السماح بمزيد من الحالات المخفية. البيان 2 | غالبًا ما يكون التصفية التعاونية نموذجًا مفيدًا لنمذجة تفضيلات الأفلام الخاصة بالمستخدمين.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
أنت تقوم بتدريب نموذج انحدار خطي على مهمة تقدير بسيطة ، ولاحظ أن النموذج يتلاءم مع البيانات. قررت إضافة تسوية $ \ ell_2 $ لمعاقبة الأوزان. عند زيادة معامل تسوية $ \ ell_2 $ ، ماذا سيحدث لتحيز النموذج وتباينه؟,زيادة التحيز زيادة التباين,زيادة التحيز انخفاض التباين,انخفاض التحيز زيادة التباين,انخفاض التحيز انخفاض التباين,B
أي أمر (أوامر) PyTorch 1.8 ينتج 10 دولارات × 5 دولارات مصفوفة غاوسية مع كل إدخال i.i.d. مأخوذة من $ \ mathcal {N} (\ mu = 5، \ sigma ^ 2 = 16) $ و $ 10 \ times 10 $ مصفوفة موحدة مع كل إدخال i.i.d. مأخوذة من U $ [-1،1) $؟,\ texttt {5 + torch.randn (10،5) * 16} ؛ \ texttt {torch.rand (10،10 ، منخفض = -1 ، مرتفع = 1)},\ texttt {5 + torch.randn (10،5) * 16} ؛ \ texttt {(torch.rand (10،10) - 0.5) / 0.5},\ texttt {5 + torch.randn (10،5) * 4} ؛ \ texttt {2 * torch.rand (10،10) - 1},\ texttt {torch.normal (torch.ones (10،5) * 5، torch.ones (5،5) * 16)} ؛ \ texttt {2 * torch.rand (10،10) - 1},C
البيان 1 | التدرج اللوني لـ ReLU هو صفر لـ $ x <0 $ ، والتدرج السيني $ \ sigma (x) (1- \ sigma (x)) \ le \ frac {1} {4} $ لكل $ x $. البيان 2 | يحتوي السيني على تدرج مستمر بينما يحتوي ReLU على تدرج متقطع.,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,A
ما هو صحيح فيما يتعلق بمطابقة الدُفعات؟,بعد تطبيق تسوية الدُفعة ، ستتبع عمليات تنشيط الطبقة التوزيع القياسي Gaussian.,تصبح معلمة التحيز للطبقات الأفينية زائدة عن الحاجة إذا اتبعت طبقة تسوية دفعية بعد ذلك مباشرة.,يجب تغيير تهيئة الوزن القياسي عند استخدام تسوية الدُفعات.,التطبيع الدفعي يعادل تطبيع الطبقة للشبكات العصبية التلافيفية.,B
لنفترض أن لدينا وظيفة الهدف التالية: $ \ argmin_ {w} \ frac {1} {2} \ norm {Xw-y} ^ 2_2 + \ frac {1} {2} \ gamma \ norm {w} ^ 2_2 $ ما تدرج $ \ frac {1} {2} \ norm {Xw-y} ^ 2_2 + \ frac {1} {2} \ lambda \ norm {w} ^ 2_2 $ بالنسبة إلى $ w $؟,$ \ nabla_w f (w) = (X ^ \ top X + \ lambda I) w - X ^ \ top y + \ lambda w $,$ \ nabla_w f (w) = X ^ \ top X w - X ^ \ top y + \ lambda $,$ \ nabla_w f (w) = X ^ \ top X w - X ^ \ top y + \ lambda w $,$ \ nabla_w f (w) = X ^ \ top X w - X ^ \ top y + (\ lambda + 1) w $,C
أي مما يلي ينطبق على نواة الالتواء؟,لن يؤدي تحويل صورة باستخدام $ \ begin {bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \ end {bmatrix} $ إلى تغيير الصورة,لن يؤدي تحويل الصورة باستخدام $ \ begin {bmatrix} 0 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0 \ end {bmatrix} $ إلى تغيير الصورة,لن يؤدي تحويل صورة باستخدام $ \ begin {bmatrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \ end {bmatrix} $ إلى تغيير الصورة,لن يؤدي تحويل الصورة باستخدام $ \ begin {bmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \ end {bmatrix} $ إلى تغيير الصورة,B
أي مما يلي خاطئ؟,تتنبأ نماذج التجزئة الدلالية بفئة كل بكسل ، بينما تتنبأ المصنفات متعددة الفئات بفئة الصورة بأكملها.,المربع المحيط مع IoU (تقاطع على الاتحاد) يساوي $ 96 \٪ $ من المحتمل أن يُعتبر موجبًا حقيقيًا.,عندما لا يتوافق الصندوق المحيط المتوقع مع أي كائن في المشهد ، فإنه يعتبر إيجابيًا كاذبًا.,من المحتمل أن يتم اعتبار الصندوق المحيط به IoU (تقاطع على الاتحاد) يساوي $ 3 \٪ $ على أنه سلبي كاذب.,D
أي مما يلي خاطئ؟,الشبكة التالية المتصلة بالكامل بدون وظائف التنشيط خطية: $ g_3 (g_2 (g_1 (x))) $ ، حيث $ g_i (x) = W_i x $ و $ W_i $ مصفوفتان.,Leaky ReLU $ \ max \ {0.01x، x \} $ محدب.,مجموعة من ReLUs مثل $ ReLU (x) - ReLU (x-1) $ محدب.,الخسارة $ \ log \ sigma (x) = - \ log (1 + e ^ {- x}) $ مقعرة,C
نقوم بتدريب شبكة متصلة بالكامل بطبقتين مخفيتين للتنبؤ بأسعار المساكن. المدخلات هي 100 دولار - الأبعاد ، ولها العديد من الميزات مثل عدد الأقدام المربعة ، ومتوسط ​​دخل الأسرة ، وما إلى ذلك. الطبقة المخفية الأولى لها 1000 دولار من التنشيط. الطبقة الثانية المخفية لها تنشيطات بقيمة 10 دولارات. الناتج هو رقم قياسي يمثل سعر المنزل. بافتراض وجود شبكة فانيليا مع تحويلات أفيني وبدون تطبيع دفعي ولا توجد معلمات قابلة للتعلم في وظيفة التنشيط ، كم عدد المعلمات التي تمتلكها هذه الشبكة؟,١١١٠٢١,١١٠٠١٠,١١١١١٠,١١٠٠١١,A
البيان 1 | مشتق السيني $ \ sigma (x) = (1 + e ^ {- x}) ^ {- 1} $ بالنسبة إلى $ x $ يساوي $ \ text {Var} (B) $ حيث $ B \ sim \ text {Bern} (\ sigma (x)) $ هو متغير برنولي العشوائي. البيان 2 | يؤدي تعيين معلمات التحيز في كل طبقة من الشبكة العصبية إلى 0 إلى تغيير مقايضة تباين التحيز بحيث يزيد تباين النموذج ويقل انحياز النموذج,حقيقي حقيقي,خطأ ، خطأ,خطأ صحيح,خطأ صحيح,C
