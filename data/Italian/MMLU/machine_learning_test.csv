Affermazione 1| Lo stimatore di regressione lineare ha la varianza più piccola tra tutti gli stimatori imparziali. Affermazione 2| I coefficienti α assegnati ai classificatori assemblati da AdaBoost sono sempre non negativi.,"True, True","Falso, Falso",Vero falso,Falsa verità,D
Affermazione 1| RoBERTa esegue il pretraining su un corpus che è approssimativamente 10 volte più grande del corpus su cui BERT si è preaddestrato. Affermazione 2| ResNeXts nel 2018 utilizzava solitamente funzioni di attivazione tanh.,"True, True","Falso, Falso",Vero falso,Falsa verità,C
"Affermazione 1| Le macchine vettoriali di supporto, come i modelli di regressione logistica, forniscono una distribuzione di probabilità sulle possibili etichette dato un esempio di input. Affermazione 2| Ci aspetteremmo che i vettori di supporto rimangano gli stessi in generale mentre ci spostiamo da un kernel lineare a kernel polinomiali di ordine superiore.","True, True","Falso, Falso",Vero falso,Falsa verità,B
"Un problema di machine learning coinvolge quattro attributi più una classe. Gli attributi hanno 3, 2, 2 e 2 valori possibili ciascuno. La classe ha 3 possibili valori. Quanti esempi diversi massimi possibili ci sono?",12,24,48,72,D
"A partire dal 2020, quale architettura è la migliore per classificare le immagini ad alta risoluzione?",reti convoluzionali,reti grafiche,reti completamente connesse,Reti RBF,A
Affermazione 1| La probabilità logaritmica dei dati aumenterà sempre attraverso iterazioni successive dell'algoritmo di massimizzazione delle aspettative. Affermazione 2| Uno svantaggio di Q-learning è che può essere utilizzato solo quando lo studente ha una conoscenza preliminare di come le sue azioni influenzano il suo ambiente.,"True, True","Falso, Falso",Vero falso,Falsa verità,B
Diciamo che abbiamo calcolato il gradiente della nostra funzione di costo e lo abbiamo memorizzato in un vettore g. Qual è il costo di un aggiornamento della discesa del gradiente dato il gradiente?,O(D),O(N),O(ND),O(ND^2),A
"Affermazione 1| Per una variabile casuale continua x e la sua funzione di distribuzione di probabilità p(x), vale che 0 ≤ p(x) ≤ 1 per ogni x. Affermazione 2| L'albero decisionale viene appreso riducendo al minimo il guadagno di informazioni.","True, True","Falso, Falso",Vero falso,Falsa verità,B
Considera la rete bayesiana fornita di seguito. Quanti parametri indipendenti sono necessari per questa rete bayesiana H -> U <- P <- W?,2,4,8,16,C
"Man mano che il numero di esempi di addestramento va all'infinito, il tuo modello addestrato su quei dati avrà:",Varianza inferiore,Varianza maggiore,Stessa varianza,Nessuna delle precedenti,A
Affermazione 1| L'insieme di tutti i rettangoli nel piano 2D (che include i rettangoli non allineati all'asse) può frantumare un insieme di 5 punti. Affermazione 2| La dimensione VC del classificatore k-Nearest Neighbor quando k = 1 è infinita.,"True, True","Falso, Falso",Vero falso,Falsa verità,A
_ si riferisce a un modello che non può né modellare i dati di addestramento né generalizzare a nuovi dati.,buon adattamento,sovradimensionamento,inadeguato,tutti i precedenti,C
Affermazione 1| Il punteggio F1 può essere particolarmente utile per i set di dati con squilibrio elevato della classe. Affermazione 2| L'area sotto la curva ROC è una delle principali metriche utilizzate per valutare i rilevatori di anomalie.,"True, True","Falso, Falso",Vero falso,Falsa verità,A
"Affermazione 1| L'algoritmo di backpropagation apprende una rete neurale ottimale a livello globale con livelli nascosti. Affermazione 2| La dimensione VC di una linea dovrebbe essere al massimo 2, poiché posso trovare almeno un caso di 3 punti che non possono essere frantumati da nessuna linea.","True, True","Falso, Falso",Vero falso,Falsa verità,B
Alta entropia significa che le partizioni nella classificazione lo sono,pure,not pure,useful,useless,B
"Affermazione 1| La normalizzazione del livello viene utilizzata nel documento ResNet originale, non nella normalizzazione batch. Affermazione 2| I DCGAN usano l'auto-attenzione per stabilizzare l'allenamento.","True, True","Falso, Falso",Vero falso,Falsa verità,B
"Nella creazione di un modello di regressione lineare per un particolare set di dati, si osserva il coefficiente di una delle caratteristiche con un valore negativo relativamente elevato. Questo lo suggerisce",Questa caratteristica ha un forte effetto sul modello (dovrebbe essere mantenuta),Questa caratteristica non ha un forte effetto sul modello (dovrebbe essere ignorata),Non è possibile commentare l'importanza di questa caratteristica senza ulteriori informazioni,Nulla può essere determinato.,C
"Per una rete neurale, quale di queste ipotesi strutturali è quella che influisce maggiormente sul compromesso tra underfitting (ovvero un modello ad alta distorsione) e overfitting (ovvero un modello ad alta varianza):",Il numero di nodi nascosti,Il tasso di apprendimento,La scelta iniziale dei pesi,L'uso di un input unitario a termine costante,A
"Per la regressione polinomiale, quale di queste ipotesi strutturali è quella che influisce maggiormente sul compromesso tra underfitting e overfitting:",Il grado polinomiale,Se apprendiamo i pesi per inversione di matrice o discesa del gradiente,La varianza presunta del rumore gaussiano,L'uso di un input unitario a termine costante,A
"Affermazione 1| A partire dal 2020, alcuni modelli raggiungono una precisione superiore al 98% su CIFAR-10. Affermazione 2| I ResNet originali non sono stati ottimizzati con l'ottimizzatore Adam.","True, True","Falso, Falso",Vero falso,Falsa verità,A
L'algoritmo K-significa:,Richiede che la dimensione dello spazio delle caratteristiche non sia maggiore del numero di campioni,Ha il valore più piccolo della funzione obiettivo quando K = 1,Riduce al minimo la varianza all'interno della classe per un determinato numero di cluster,Converge all'ottimo globale se e solo se le medie iniziali sono scelte come alcuni dei campioni stessi,C
Affermazione 1| I VGGNet hanno kernel convoluzionali di larghezza e altezza inferiori rispetto ai kernel di primo strato di AlexNet. Affermazione 2| Le procedure di inizializzazione del peso dipendente dai dati sono state introdotte prima della normalizzazione batch.,"True, True","Falso, Falso",Vero falso,Falsa verità,A
"Qual è il rango della seguente matrice? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]",0,1,2,3,B
"Affermazione 1| La stima della densità (utilizzando, ad esempio, lo stimatore della densità del kernel) può essere utilizzata per eseguire la classificazione. Affermazione 2| La corrispondenza tra regressione logistica e Gaussian Naive Bayes (con covarianze di classi di identità) significa che esiste una corrispondenza biunivoca tra i parametri dei due classificatori.","True, True","Falso, Falso",Vero falso,Falsa verità,C
Supponiamo di voler eseguire il clustering su dati spaziali come le posizioni geometriche delle case. Desideriamo produrre grappoli di molte dimensioni e forme diverse. Quale dei seguenti metodi è il più appropriato?,Alberi decisionali,Clustering basato sulla densità,Clustering basato su modello,K-significa raggruppamento,B
"Affermazione 1| In AdaBoost i pesi degli esempi classificati erroneamente aumentano dello stesso fattore moltiplicativo. Affermazione 2| In AdaBoost, l'errore di addestramento ponderato e_t dell't-esimo classificatore debole sui dati di addestramento con pesi D_t tende ad aumentare in funzione di t.","True, True","Falso, Falso",Vero falso,Falsa verità,A
Le stime MLE sono spesso indesiderabili perché,sono di parte,hanno varianza elevata,non sono stimatori coerenti,Nessuna delle precedenti,B
"La complessità computazionale della discesa del gradiente è,",lineare in D,lineare in N,polinomio in D,dipendente dal numero di iterazioni,C
La media dell'output di più alberi decisionali aiuta _.,Aumentare il pregiudizio,Diminuire il pregiudizio,Aumentare la varianza,Diminuire la varianza,D
Il modello ottenuto applicando la regressione lineare sul sottoinsieme di caratteristiche identificato può differire dal modello ottenuto al termine del processo di identificazione del sottoinsieme durante,Selezione del miglior sottoinsieme,Selezione graduale in avanti,Selezione saggia della fase avanzata,Tutti i precedenti,C
Reti neurali:,Ottimizzazione di una funzione obiettivo convessa,Può essere addestrato solo con la discesa del gradiente stocastico,Può utilizzare un mix di diverse funzioni di attivazione,Nessuna delle precedenti,C
"Supponiamo che l'incidenza di una malattia D sia di circa 5 casi ogni 100 persone (ovvero P(D) = 0,05). Lascia che la variabile casuale booleana D significhi un paziente ""ha la malattia D"" e lascia che la variabile casuale booleana TP stia per ""test positivi"". È noto che i test per la malattia D sono molto accurati, nel senso che la probabilità di risultare positivi quando si ha la malattia è 0,99 e la probabilità di risultare negativi quando non si ha la malattia è 0,97. Qual è P(TP), la probabilità a priori di risultare positivo al test.",0.0368,0.473,0.078,Nessuna delle precedenti,C
"Affermazione 1| Dopo essere stato mappato nello spazio delle caratteristiche Q tramite una funzione kernel a base radiale, 1-NN utilizzando la distanza euclidea non pesata potrebbe essere in grado di ottenere prestazioni di classificazione migliori rispetto allo spazio originale (sebbene non possiamo garantirlo). Affermazione 2| La dimensione VC di un Perceptron è inferiore alla dimensione VC di un semplice SVM lineare.","True, True","Falso, Falso",Vero falso,Falsa verità,B
Lo svantaggio della ricerca Grid è,Non può essere applicato a funzioni non differenziabili.,Non può essere applicato a funzioni non continue.,È difficile da implementare.,Funziona ragionevolmente lentamente per la regressione lineare multipla.,D
Prevedere la quantità di precipitazioni in una regione sulla base di vari segnali è un ______ problema.,Apprendimento supervisionato,Apprendimento non supervisionato,Clustering,Nessuna delle precedenti,A
Quale delle seguenti frasi è FALSA riguardo alla regressione?,Mette in relazione gli input con gli output.,È usato per la previsione.,Può essere utilizzato per l'interpretazione.,Scopre relazioni causali,D
Quale dei seguenti è il motivo principale per potare un albero decisionale?,Per risparmiare tempo di elaborazione durante i test,Per risparmiare spazio per l'archiviazione dell'albero decisionale,Per ridurre l'errore del training set,Per evitare di sovradimensionare il training set,D
Affermazione 1| Lo stimatore della densità del kernel equivale a eseguire la regressione del kernel con il valore Yi = 1/n in ogni punto Xi nel set di dati originale. Affermazione 2| La profondità di un albero decisionale appreso può essere maggiore del numero di esempi di addestramento utilizzati per creare l'albero.,"True, True","Falso, Falso",Vero falso,Falsa verità,B
Supponiamo che il tuo modello sia overfitting. Quale dei seguenti NON è un modo valido per cercare di ridurre l'overfitting?,Aumentare la quantità di dati di allenamento.,Migliorare l'algoritmo di ottimizzazione utilizzato per la minimizzazione degli errori.,Diminuire la complessità del modello.,Ridurre il rumore nei dati di addestramento.,B
Affermazione 1| La funzione softmax è comunemente usata nella regressione logistica multiclasse. Affermazione 2| La temperatura di una distribuzione softmax non uniforme influisce sulla sua entropia.,"True, True","Falso, Falso",Vero falso,Falsa verità,A
Quale delle seguenti affermazioni è/sono vera per quanto riguarda un SVM?,"Per punti dati bidimensionali, l'iperpiano di separazione appreso da un SVM lineare sarà una linea retta.","In teoria, un kernel gaussiano SVM non può modellare alcun iperpiano di separazione complesso.","Per ogni funzione del kernel utilizzata in una SVM, è possibile ottenere un'espansione di base in forma chiusa equivalente.",L'overfitting in una SVM non è una funzione del numero di vettori di supporto.,A
"Quale delle seguenti è la probabilità congiunta di H, U, P e W descritta dalla data rete bayesiana H -> U <- P <- W? [nota: come prodotto delle probabilità condizionate]","P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)",Nessuna delle precedenti,C
"Affermazione 1| Poiché la dimensione VC per un SVM con un kernel a base radiale è infinita, tale SVM deve essere peggiore di un SVM con kernel polinomiale che ha una dimensione VC finita. Affermazione 2| Una rete neurale a due livelli con funzioni di attivazione lineare è essenzialmente una combinazione ponderata di separatori lineari, addestrati su un dato set di dati; l'algoritmo di boosting basato su separatori lineari trova anche una combinazione di separatori lineari, quindi questi due algoritmi daranno lo stesso risultato.","True, True","Falso, Falso",Vero falso,Falsa verità,B
Affermazione 1| L'algoritmo ID3 è garantito per trovare l'albero decisionale ottimale. Affermazione 2| Considera una distribuzione di probabilità continua con densità f() che è diversa da zero ovunque. La probabilità di un valore x è uguale a f(x).,"True, True","Falso, Falso",Vero falso,Falsa verità,B
"Data una rete neurale con N nodi di input, nessun livello nascosto, un nodo di output, con le funzioni di perdita di entropia e attivazione del sigmoide, quale dei seguenti algoritmi (con gli iperparametri e l'inizializzazione appropriati) può essere utilizzato per trovare l'optimum globale?",Discesa del gradiente stocastico,Discesa gradiente mini-batch,Discesa gradiente batch,Tutti i precedenti,D
"Aggiungendo più funzioni di base in un modello lineare, scegli l'opzione più probabile:",Diminuisce la distorsione del modello,Diminuisce il bias di stima,Diminuisce la varianza,Non influisce su bias e varianza,A
Considera la rete bayesiana fornita di seguito. Di quanti parametri indipendenti avremmo bisogno se non facessimo ipotesi sull'indipendenza o sull'indipendenza condizionale H -> U <- P <- W?,3,4,7,15,D
Un altro termine per il rilevamento fuori distribuzione è?,rilevamento anomalie,rilevamento di una classe,robustezza del mismatch train-test,rilevamento dello sfondo,A
"Affermazione 1| Impariamo un classificatore f potenziando gli studenti deboli h. La forma funzionale del limite decisionale di f è la stessa di h, ma con parametri differenti. (ad esempio, se h era un classificatore lineare, allora anche f è un classificatore lineare). Affermazione 2| La convalida incrociata può essere utilizzata per selezionare il numero di iterazioni nel potenziamento; questa procedura può aiutare a ridurre l'overfitting.","True, True","Falso, Falso",Vero falso,Falsa verità,D
Affermazione 1| Le reti autostradali sono state introdotte dopo ResNets ed evitano il max pooling a favore delle convoluzioni. Affermazione 2| I DenseNet di solito costano più memoria rispetto ai ResNet.,"True, True","Falso, Falso",Vero falso,Falsa verità,D
"Se N è il numero di istanze nel set di dati di addestramento, i vicini più vicini hanno un tempo di esecuzione della classificazione di",O(1),O( N ),O(log N ),O( N^2 ),B
"Affermazione 1| I ResNet e i Transformer originali sono reti neurali feedforward. Affermazione 2| I Transformers originali usano l'auto-attenzione, ma il ResNet originale no.","True, True","Falso, Falso",Vero falso,Falsa verità,A
"Affermazione 1| I RELU non sono monotoni, ma i sigmoidi sono monotoni. Affermazione 2| Le reti neurali addestrate con la discesa del gradiente con alta probabilità convergono all'ottimo globale.","True, True","Falso, Falso",Vero falso,Falsa verità,D
L'output numerico di un nodo sigmoideo in una rete neurale:,"È illimitato, comprende tutti i numeri reali.","È illimitato, comprende tutti i numeri interi.",È limitato tra 0 e 1.,È limitato tra -1 e 1.,C
Quale dei seguenti può essere utilizzato solo quando i dati di addestramento sono separabili linearmente?,SVM lineare con margine rigido.,Regressione logistica lineare.,Margine morbido lineare SVM.,Il metodo del centroide.,A
Quali dei seguenti sono gli algoritmi di clustering spaziale?,Clustering basato sul partizionamento,K-significa raggruppamento,Clustering basato su griglia,Tutti i precedenti,D
Affermazione 1| I limiti di decisione del margine massimo che supportano la costruzione delle macchine vettoriali hanno l'errore di generalizzazione più basso tra tutti i classificatori lineari. Affermazione 2| Qualsiasi confine decisionale che otteniamo da un modello generativo con distribuzioni gaussiane condizionali di classe potrebbe in linea di principio essere riprodotto con un SVM e un nucleo polinomiale di grado inferiore o uguale a tre.,"True, True","Falso, Falso",Vero falso,Falsa verità,D
Affermazione 1| La regolarizzazione L2 dei modelli lineari tende a rendere i modelli più radi rispetto alla regolarizzazione L1. Affermazione 2| Le connessioni residue possono essere trovate in ResNets e Transformers.,"True, True","Falso, Falso",Vero falso,Falsa verità,D
"Supponiamo di voler calcolare P(H|E, F) e di non avere informazioni di indipendenza condizionale. Quale delle seguenti serie di numeri è sufficiente per il calcolo?","P(E, F), P(H), P(E|H), P(F|H)","P(E, F), P(H), P(E, F|H)","P(H), P(E|H), P(F|H)","P(E, F), P(E|H), P(F|H)",B
Quale tra i seguenti previene l'overfitting quando eseguiamo il bagging?,L'uso del campionamento con sostituzione come tecnica di campionamento,L'uso di classificatori deboli,L'uso di algoritmi di classificazione che non sono soggetti a overfitting,La pratica di convalida eseguita su ogni classificatore addestrato,B
"Affermazione 1| PCA e Spectral Clustering (come quello di Andrew Ng) eseguono la composizione automatica su due diverse matrici. Tuttavia, le dimensioni di queste due matrici sono le stesse. Affermazione 2| Poiché la classificazione è un caso speciale di regressione, la regressione logistica è un caso speciale di regressione lineare.","True, True","Falso, Falso",Vero falso,Falsa verità,B
"Affermazione 1| The Stanford Sentiment Treebank conteneva recensioni di film, non recensioni di libri. Affermazione 2| Il Penn Treebank è stato utilizzato per la modellazione del linguaggio.","True, True","Falso, Falso",Vero falso,Falsa verità,A
"Qual è la dimensionalità dello spazio nullo della seguente matrice? LA = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]]",0,1,2,3,C
Cosa sono i vettori di supporto?,Gli esempi più lontani dal confine decisionale.,Gli unici esempi necessari per calcolare f(x) in una SVM.,Il centroide dei dati.,Tutti gli esempi che hanno peso αk diverso da zero in una SVM.,B
Affermazione 1| I parametri di Word2Vec non sono stati inizializzati utilizzando una macchina Boltzman limitata. Affermazione 2| La funzione tanh è una funzione di attivazione non lineare.,"True, True","Falso, Falso",Vero falso,Falsa verità,A
"Se la tua perdita di allenamento aumenta con il numero di epoche, quale dei seguenti potrebbe essere un possibile problema con il processo di apprendimento?",La regolarizzazione è troppo bassa e il modello è overfitting,La regolarizzazione è troppo alta e il modello è insufficiente,La dimensione del passo è troppo grande,La dimensione del passo è troppo piccola,C
"Supponiamo che l'incidenza di una malattia D sia di circa 5 casi ogni 100 persone (ovvero P(D) = 0,05). Lascia che la variabile casuale booleana D significhi un paziente ""ha la malattia D"" e lascia che la variabile casuale booleana TP stia per ""test positivi"". È noto che i test per la malattia D sono molto accurati, nel senso che la probabilità di risultare positivi quando si ha la malattia è 0,99 e la probabilità di risultare negativi quando non si ha la malattia è 0,97. Qual è P(D | TP), la probabilità a posteriori di avere la malattia D quando il test è positivo?",0.0495,0.078,0.635,0.97,C
"Affermazione 1| I risultati del machine learning tradizionale presuppongono che il treno e i set di test siano indipendenti e distribuiti in modo identico. Affermazione 2| Nel 2017, i modelli COCO venivano solitamente preaddestrati su ImageNet.","True, True","Falso, Falso",Vero falso,Falsa verità,A
"Affermazione 1| I valori dei margini ottenuti da due diversi kernel K1(x, x0) e K2(x, x0) sullo stesso set di addestramento non ci dicono quale classificatore funzionerà meglio sul set di test. Affermazione 2| La funzione di attivazione di BERT è il GELU.","True, True","Falso, Falso",Vero falso,Falsa verità,A
Quale dei seguenti è un algoritmo di clustering nell'apprendimento automatico?,Massimizzazione delle aspettative,CART,Bayes ingenuo gaussiano,Apriori,A
"Hai appena finito di addestrare un albero decisionale per la classificazione dello spam e sta ottenendo prestazioni anormalmente negative sia sul set di addestramento che su quello di test. Sai che la tua implementazione non ha bug, quindi cosa potrebbe causare il problema?",I tuoi alberi decisionali sono troppo superficiali.,Devi aumentare il tasso di apprendimento.,Stai esagerando.,Nessuna delle precedenti.,A
La convalida incrociata K-fold è,lineare in K,quadratico in K,cubic in K,esponenziale in K,A
"Affermazione 1| Le reti neurali su scala industriale sono normalmente addestrate su CPU, non su GPU. Affermazione 2| Il modello ResNet-50 ha oltre 1 miliardo di parametri.","True, True","Falso, Falso",Vero falso,Falsa verità,B
"Date due variabili casuali booleane, A e B, dove P(A) = 1/2, P(B) = 1/3 e P(A | ¬B) = 1/4, quanto vale P(A | B) ?",1/6,1/4,3/4,1,D
I rischi esistenziali posti dall'IA sono più comunemente associati a quale dei seguenti professori?,Nando de Freitas,Yann LeCun,Stuart Russel,Jitendra Malik,C
Affermazione 1| La massimizzazione della probabilità del modello di regressione logistica produce più ottimi locali. Affermazione 2| Nessun classificatore può fare meglio di un ingenuo classificatore Bayes se la distribuzione dei dati è nota.,"True, True","Falso, Falso",Vero falso,Falsa verità,B
"Per la regressione del kernel, quale di queste ipotesi strutturali è quella che influisce maggiormente sul compromesso tra underfitting e overfitting:",Se la funzione del kernel è gaussiana o triangolare oa forma di scatola,Se usiamo le metriche euclidee rispetto a L1 o L∞,La larghezza del nocciolo,L'altezza massima della funzione kernel,C
"Affermazione 1| L'algoritmo di apprendimento SVM è garantito per trovare l'ipotesi ottimale a livello globale rispetto alla sua funzione oggetto. Affermazione 2| Dopo essere stato mappato nello spazio delle caratteristiche Q tramite una funzione del kernel a base radiale, un Perceptron potrebbe essere in grado di ottenere prestazioni di classificazione migliori rispetto al suo spazio originale (sebbene non possiamo garantirlo).","True, True","Falso, Falso",Vero falso,Falsa verità,A
"Per un classificatore bayesiano gaussiano, quale di queste ipotesi strutturali è quella che influisce maggiormente sul compromesso tra underfitting e overfitting:",Se apprendiamo i centri di classe per massima verosimiglianza o gradiente discendente,Se assumiamo matrici di covarianza di classe completa o matrici di covarianza di classe diagonale,Se abbiamo priori di classe uguale o priori stimati dai dati.,Se permettiamo alle classi di avere vettori medi diversi o le forziamo a condividere lo stesso vettore medio,B
Affermazione 1| L'overfitting è più probabile quando il set di dati di addestramento è piccolo. Affermazione 2| L'overfitting è più probabile quando lo spazio dell'ipotesi è piccolo.,"True, True","Falso, Falso",Vero falso,Falsa verità,D
"Affermazione 1| Oltre a EM, la discesa del gradiente può essere utilizzata per eseguire l'inferenza o l'apprendimento sul modello di miscela gaussiana. Dichiarazione 2 | Assumendo un numero fisso di attributi, un classificatore ottimale di Bayes basato sulla gaussiana può essere appreso in tempo lineare nel numero di record nel set di dati.","True, True","Falso, Falso",Vero falso,Falsa verità,A
"Affermazione 1| In una rete bayesiana, i risultati dell'inferenza dell'algoritmo dell'albero di giunzione sono gli stessi dei risultati dell'inferenza dell'eliminazione delle variabili. Affermazione 2| Se due variabili casuali X e Y sono condizionatamente indipendenti data un'altra variabile casuale Z, allora nella rete bayesiana corrispondente, i nodi per X e Y sono separati da d dato Z.","True, True","Falso, Falso",Vero falso,Falsa verità,C
"Dato un ampio set di dati di cartelle cliniche di pazienti affetti da malattie cardiache, prova a scoprire se potrebbero esserci diversi gruppi di tali pazienti per i quali potremmo adattare trattamenti separati. Che tipo di problema di apprendimento è questo?",Apprendimento supervisionato,Apprendimento non supervisionato,Sia a che B),Nè a nè B),B
Cosa faresti in PCA per ottenere la stessa proiezione di SVD?,Trasforma i dati in media nulla,Trasforma i dati in mediana zero,Non possibile,Nessuna di queste,A
"Affermazione 1| L'errore di addestramento del classificatore 1-neest neighbor è 0. Istruzione 2| Man mano che il numero di punti dati cresce all'infinito, la stima MAP si avvicina alla stima MLE per tutti i possibili precedenti. In altre parole, dati dati sufficienti, la scelta del priore è irrilevante.","True, True","Falso, Falso",Vero falso,Falsa verità,C
"Quando si esegue la regressione ai minimi quadrati con regolarizzazione (supponendo che l'ottimizzazione possa essere eseguita esattamente), aumentando il valore del parametro di regolarizzazione λ l'errore di test.",non diminuirà mai l'errore di addestramento.,non aumenterà mai l'errore di addestramento.,non diminuirà mai l'errore di test.,non aumenterà mai,A
Quale delle seguenti definizioni descrive meglio quali approcci discriminatori tentano di modellare? (w sono i parametri nel modello),"p(y|x, w)","p(y, x)","p(w|x, w)",Nessuna delle precedenti,A
Affermazione 1| Le prestazioni della classificazione CIFAR-10 per le reti neurali a convoluzione possono superare il 95%. Affermazione 2| Gli insiemi di reti neurali non migliorano l'accuratezza della classificazione poiché le rappresentazioni che apprendono sono altamente correlate.,"True, True","Falso, Falso",Vero falso,Falsa verità,C
Su quale dei seguenti punti bayesiani e frequentisti sarebbero in disaccordo?,L'uso di un modello di rumore non gaussiano nella regressione probabilistica.,L'uso di modelli probabilistici per la regressione.,L'uso di distribuzioni a priori sui parametri in un modello probabilistico.,L'uso dei priori di classe nell'analisi discriminante gaussiana.,C
"Affermazione 1| La metrica BLEU utilizza la precisione, mentre la metrica ROGUE utilizza il richiamo. Affermazione 2| I modelli di markov nascosti venivano spesso usati per modellare frasi inglesi.","True, True","Falso, Falso",Vero falso,Falsa verità,A
Affermazione 1| ImageNet ha immagini di varie risoluzioni. Affermazione 2| Caltech-101 ha più immagini di ImageNet.,"True, True","Falso, Falso",Vero falso,Falsa verità,C
Quale delle seguenti opzioni è più appropriata per eseguire la selezione delle funzionalità?,Ridge,Lasso,sia a che B),nè a nè B),B
Supponiamo che ti venga fornito un algoritmo EM che trova stime di massima verosimiglianza per un modello con variabili latenti. Ti viene chiesto di modificare l'algoritmo in modo che trovi invece le stime MAP. Quale passaggio o passaggi è necessario modificare?,Aspettativa,Massimizzazione,Nessuna modifica necessaria,Both,B
"Per un classificatore bayesiano gaussiano, quale di queste ipotesi strutturali è quella che influisce maggiormente sul compromesso tra underfitting e overfitting:",Se apprendiamo i centri di classe per massima verosimiglianza o gradiente discendente,Se assumiamo matrici di covarianza di classe completa o matrici di covarianza di classe diagonale,Se abbiamo priori di classe uguale o priori stimati dai dati,Se permettiamo alle classi di avere vettori medi diversi o le forziamo a condividere lo stesso vettore medio,B
"Affermazione 1| Per ogni coppia di variabili x e y aventi distribuzione congiunta p(x, y), abbiamo sempre H[x, y] ≥ H[x] + H[y] dove H è la funzione di entropia. Affermazione 2| Per alcuni grafici orientati, la moralizzazione diminuisce il numero di spigoli presenti nel grafico.","True, True","Falso, Falso",Vero falso,Falsa verità,B
Quale dei seguenti NON è un apprendimento supervisionato?,PCA,Albero decisionale,Regressione lineare,Bayesiano ingenuo,A
Affermazione 1| La convergenza di una rete neurale dipende dal tasso di apprendimento. Affermazione 2| Dropout moltiplica per zero i valori di attivazione scelti casualmente.,"True, True","Falso, Falso",Vero falso,Falsa verità,A
"Quale dei seguenti è uguale a P(A, B, C) date le variabili casuali booleane A, B e C e nessuna ipotesi di indipendenza o indipendenza condizionale tra nessuna di esse?",P(A | B) * P(B | C) * P(C | A),"P(C | A, B) * P(A) * P(B)","P(A, B | C) * P(C)","P(A | B, C) * P(B | A, C) * P(C | A, B)",C
Quale delle seguenti attività può essere risolta nel modo migliore utilizzando il clustering.,Previsione della quantità di precipitazioni in base a vari segnali,Rilevamento di transazioni fraudolente con carta di credito,Addestrare un robot per risolvere un labirinto,Tutti i precedenti,B
"Dopo aver applicato una penalità di regolarizzazione nella regressione lineare, scopri che alcuni dei coefficienti di w sono azzerati. Quale delle seguenti sanzioni potrebbe essere stata utilizzata?",L0 norm,L1 norm,L2 norm,o A o B),D
"A e B sono due eventi. Se P(A, B) diminuisce mentre P(A) aumenta, quale delle seguenti affermazioni è vera?",P(A|B) diminuisce,P(B|A) diminuisce,P(B) diminuisce,Tutto quanto sopra,B
"Affermazione 1| Quando apprendiamo un HMM per un insieme fisso di osservazioni, supponiamo di non conoscere il vero numero di stati nascosti (che è spesso il caso), possiamo sempre aumentare la probabilità dei dati di addestramento consentendo più stati nascosti. Affermazione 2| Il filtraggio collaborativo è spesso un modello utile per modellare le preferenze cinematografiche degli utenti.","True, True","Falso, Falso",Vero falso,Falsa verità,A
"Stai addestrando un modello di regressione lineare per una semplice attività di stima e noti che il modello si adatta eccessivamente ai dati. Decidi di aggiungere la regolarizzazione $\ell_2$ per penalizzare i pesi. Aumentando il coefficiente di regolarizzazione $\ell_2$, cosa accadrà alla distorsione e alla varianza del modello?",Aumento del pregiudizio; Aumento della varianza,Aumento del pregiudizio; Diminuzione della varianza,Diminuzione del pregiudizio; Aumento della varianza,Diminuzione del pregiudizio; Diminuzione della varianza,B
"Quali comandi PyTorch 1.8 producono una matrice gaussiana $10\times 5$ con ogni voce i.i.d. campionato da $\mathcal{N}(\mu=5,\sigma^2=16)$ e una matrice uniforme $10\times 10$ con ogni voce i.i.d. campionato da $U[-1,1)$?","\texttt{5 + torcia.randn(10,5) * 16} ; \texttt{torcia.rand(10,10,basso=-1,alto=1)}","\texttt{5 + torcia.randn(10,5) * 16} ; \texttt{(torcia.rand(10,10) - 0.5) / 0.5}","\texttt{5 + torcia.randn(10,5) * 4} ; \texttt{2 * torcia.rand(10,10) - 1}","\texttt{torcia.normal(torcia.ones(10,5)*5,torcia.ones(5,5)*16)} ; \texttt{2 * torcia.rand(10,10) - 1}",C
"Affermazione 1| Il gradiente di ReLU è zero per $x<0$, e il gradiente sigmoideo $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ per ogni $x$. Affermazione 2| Il sigmoide ha un gradiente continuo e il ReLU ha un gradiente discontinuo.","True, True","Falso, Falso",Vero falso,Falsa verità,A
Qual è la verità sulla normalizzazione batch?,"Dopo aver applicato la normalizzazione batch, le attivazioni del livello seguiranno una distribuzione gaussiana standard.",Il parametro bias degli strati affini diventa ridondante se uno strato di normalizzazione batch segue immediatamente dopo.,L'inizializzazione del peso standard deve essere modificata quando si utilizza la normalizzazione batch.,La normalizzazione batch è equivalente alla normalizzazione dei livelli per le reti neurali convoluzionali.,B
Supponiamo di avere la seguente funzione obiettivo: $\argmin_{w} \frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\gamma \norm{w}^2_2$ Qual è il gradiente di $\frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\lambda \norm{w}^2_2$ rispetto a $w$?,$\nabla_w f(w) = (X^\top X + \lambda I)w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + (\lambda+1) w$,C
Quale delle seguenti affermazioni è vera per un kernel di convoluzione?,La convoluzione di un'immagine con $\begin{bmatrix}1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ non cambierebbe l'immagine,La convoluzione di un'immagine con $\begin{bmatrix}0 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ non cambierebbe l'immagine,La convoluzione di un'immagine con $\begin{bmatrix}1 & 1 & 1\\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}$ non cambierebbe l'immagine,La convoluzione di un'immagine con $\begin{bmatrix}0 & 0 & 0\\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ non cambierebbe l'immagine,B
Quale delle seguenti è falsa?,"I modelli di segmentazione semantica prevedono la classe di ciascun pixel, mentre i classificatori di immagini multiclasse prevedono la classe dell'intera immagine.",Un riquadro di delimitazione con un IoU (intersezione su unione) pari a $96\%$ verrebbe probabilmente considerato come vero positivo.,"Quando un riquadro di delimitazione previsto non corrisponde ad alcun oggetto nella scena, viene considerato un falso positivo.",Un riquadro di delimitazione con un IoU (intersezione su unione) pari a $3\%$ verrebbe probabilmente considerato come falso negativo.,D
Quale delle seguenti è falsa?,"La seguente rete completamente connessa senza funzioni di attivazione è lineare: $g_3(g_2(g_1(x)))$, dove $g_i(x) = W_i x$ e $W_i$ sono matrici.","Leaky ReLU $\max\{0.01x,x\}$ è convesso.",Una combinazione di ReLU come $ReLU(x) - ReLU(x-1)$ è convessa.,La perdita $\log \sigma(x)= -\log(1+e^{-x})$ è concava,C
"Stiamo addestrando una rete completamente connessa con due livelli nascosti per prevedere i prezzi delle case. Gli input hanno una dimensione di $ 100 $ e hanno diverse caratteristiche come il numero di piedi quadrati, il reddito familiare medio, ecc. Il primo livello nascosto ha attivazioni di $ 1000 $. Il secondo livello nascosto ha attivazioni da $ 10 $. L'output è uno scalare che rappresenta il prezzo della casa. Supponendo una rete vanilla con trasformazioni affini e senza normalizzazione batch e senza parametri apprendibili nella funzione di attivazione, quanti parametri ha questa rete?",111021,110010,111110,110011,A
Affermazione 1| La derivata del sigma $\sigma(x)=(1+e^{-x})^{-1}$ rispetto a $x$ è uguale a $\text{Var}(B)$ dove $B \sim \text{Bern}(\sigma(x))$ è una variabile casuale di Bernoulli. Affermazione 2| L'impostazione dei parametri di bias in ogni livello della rete neurale su 0 modifica il compromesso bias-varianza in modo tale che la varianza del modello aumenti e il bias del modello diminuisca,"True, True","Falso, Falso",Vero falso,Falsa verità,C
